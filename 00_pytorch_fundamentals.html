<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>00 - PyTorch 기초 – 파이토치 딥러닝 입문</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./01_pytorch_workflow.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-841b73d05e5bc75123d26cb7b2f11c52.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./00_pytorch_fundamentals.html"><span class="chapter-title">00 - PyTorch 기초</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">파이토치 딥러닝 입문</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">딥러닝을 위한 PyTorch 배우기</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_pytorch_fundamentals.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">00 - PyTorch 기초</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_pytorch_workflow.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">01 - PyTorch 워크플로우</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_pytorch_classification.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">02 - PyTorch 신경망 분류</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_pytorch_computer_vision.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">03 - PyTorch 컴퓨터 비전</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_pytorch_custom_datasets.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">04 - PyTorch 사용자 정의 데이터셋</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_pytorch_going_modular.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">05 - PyTorch 모듈화</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_pytorch_transfer_learning.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">06 - PyTorch 전이 학습</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_pytorch_experiment_tracking.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">07 - PyTorch 실험 추적</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_pytorch_paper_replicating.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">08 - PyTorch 논문 복제</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_pytorch_model_deployment.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">09 - PyTorch 모델 배포</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">참고 문헌</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#pytorch란-무엇인가요" id="toc-pytorch란-무엇인가요" class="nav-link active" data-scroll-target="#pytorch란-무엇인가요">PyTorch란 무엇인가요?</a></li>
  <li><a href="#pytorch는-어디에-사용되나요" id="toc-pytorch는-어디에-사용되나요" class="nav-link" data-scroll-target="#pytorch는-어디에-사용되나요">PyTorch는 어디에 사용되나요?</a></li>
  <li><a href="#누가-pytorch를-사용하나요" id="toc-누가-pytorch를-사용하나요" class="nav-link" data-scroll-target="#누가-pytorch를-사용하나요">누가 PyTorch를 사용하나요?</a></li>
  <li><a href="#왜-pytorch를-사용해야-하나요" id="toc-왜-pytorch를-사용해야-하나요" class="nav-link" data-scroll-target="#왜-pytorch를-사용해야-하나요">왜 PyTorch를 사용해야 하나요?</a></li>
  <li><a href="#이-모듈에서-다룰-내용" id="toc-이-모듈에서-다룰-내용" class="nav-link" data-scroll-target="#이-모듈에서-다룰-내용">이 모듈에서 다룰 내용</a></li>
  <li><a href="#도움을-받을-수-있는-곳" id="toc-도움을-받을-수-있는-곳" class="nav-link" data-scroll-target="#도움을-받을-수-있는-곳">도움을 받을 수 있는 곳</a></li>
  <li><a href="#pytorch-임포트하기" id="toc-pytorch-임포트하기" class="nav-link" data-scroll-target="#pytorch-임포트하기">PyTorch 임포트하기</a></li>
  <li><a href="#텐서-소개" id="toc-텐서-소개" class="nav-link" data-scroll-target="#텐서-소개">텐서 소개</a>
  <ul class="collapse">
  <li><a href="#텐서-생성하기" id="toc-텐서-생성하기" class="nav-link" data-scroll-target="#텐서-생성하기">텐서 생성하기</a></li>
  <li><a href="#무작위-텐서" id="toc-무작위-텐서" class="nav-link" data-scroll-target="#무작위-텐서">무작위 텐서</a></li>
  <li><a href="#과-1" id="toc-과-1" class="nav-link" data-scroll-target="#과-1">0과 1</a></li>
  <li><a href="#범위-및-유사-텐서-생성" id="toc-범위-및-유사-텐서-생성" class="nav-link" data-scroll-target="#범위-및-유사-텐서-생성">범위 및 유사 텐서 생성</a></li>
  <li><a href="#텐서-데이터-타입" id="toc-텐서-데이터-타입" class="nav-link" data-scroll-target="#텐서-데이터-타입">텐서 데이터 타입</a></li>
  </ul></li>
  <li><a href="#텐서에서-정보-가져오기" id="toc-텐서에서-정보-가져오기" class="nav-link" data-scroll-target="#텐서에서-정보-가져오기">텐서에서 정보 가져오기</a></li>
  <li><a href="#텐서-조작-텐서-연산" id="toc-텐서-조작-텐서-연산" class="nav-link" data-scroll-target="#텐서-조작-텐서-연산">텐서 조작 (텐서 연산)</a>
  <ul class="collapse">
  <li><a href="#기본-연산" id="toc-기본-연산" class="nav-link" data-scroll-target="#기본-연산">기본 연산</a></li>
  <li><a href="#행렬-곱셈-matrix-multiplication" id="toc-행렬-곱셈-matrix-multiplication" class="nav-link" data-scroll-target="#행렬-곱셈-matrix-multiplication">행렬 곱셈 (Matrix Multiplication)</a></li>
  </ul></li>
  <li><a href="#딥러닝에서-가장-흔한-오류-중-하나-모양-오류" id="toc-딥러닝에서-가장-흔한-오류-중-하나-모양-오류" class="nav-link" data-scroll-target="#딥러닝에서-가장-흔한-오류-중-하나-모양-오류">딥러닝에서 가장 흔한 오류 중 하나 (모양 오류)</a>
  <ul class="collapse">
  <li><a href="#최소-최대-평균-합계-등-찾기-집계" id="toc-최소-최대-평균-합계-등-찾기-집계" class="nav-link" data-scroll-target="#최소-최대-평균-합계-등-찾기-집계">최소, 최대, 평균, 합계 등 찾기 (집계)</a></li>
  <li><a href="#위치별-최소최대" id="toc-위치별-최소최대" class="nav-link" data-scroll-target="#위치별-최소최대">위치별 최소/최대</a></li>
  <li><a href="#텐서-데이터-타입-변경" id="toc-텐서-데이터-타입-변경" class="nav-link" data-scroll-target="#텐서-데이터-타입-변경">텐서 데이터 타입 변경</a></li>
  <li><a href="#재구조화-쌓기-압축-및-압축-해제-reshaping-stacking-squeezing-and-unsqueezing" id="toc-재구조화-쌓기-압축-및-압축-해제-reshaping-stacking-squeezing-and-unsqueezing" class="nav-link" data-scroll-target="#재구조화-쌓기-압축-및-압축-해제-reshaping-stacking-squeezing-and-unsqueezing">재구조화, 쌓기, 압축 및 압축 해제 (Reshaping, stacking, squeezing and unsqueezing)</a></li>
  </ul></li>
  <li><a href="#인덱싱-텐서에서-데이터-선택" id="toc-인덱싱-텐서에서-데이터-선택" class="nav-link" data-scroll-target="#인덱싱-텐서에서-데이터-선택">인덱싱 (텐서에서 데이터 선택)</a></li>
  <li><a href="#pytorch-텐서와-numpy" id="toc-pytorch-텐서와-numpy" class="nav-link" data-scroll-target="#pytorch-텐서와-numpy">PyTorch 텐서와 NumPy</a></li>
  <li><a href="#재현성-무작위성-제어하기" id="toc-재현성-무작위성-제어하기" class="nav-link" data-scroll-target="#재현성-무작위성-제어하기">재현성 (무작위성 제어하기)</a></li>
  <li><a href="#gpu에서-텐서-실행하기-및-계산-가속화" id="toc-gpu에서-텐서-실행하기-및-계산-가속화" class="nav-link" data-scroll-target="#gpu에서-텐서-실행하기-및-계산-가속화">GPU에서 텐서 실행하기 (및 계산 가속화)</a>
  <ul class="collapse">
  <li><a href="#gpu-확보하기" id="toc-gpu-확보하기" class="nav-link" data-scroll-target="#gpu-확보하기">1. GPU 확보하기</a></li>
  <li><a href="#pytorch가-gpu에서-실행되도록-하기" id="toc-pytorch가-gpu에서-실행되도록-하기" class="nav-link" data-scroll-target="#pytorch가-gpu에서-실행되도록-하기">2. PyTorch가 GPU에서 실행되도록 하기</a></li>
  <li><a href="#gpu에-텐서및-모델-넣기" id="toc-gpu에-텐서및-모델-넣기" class="nav-link" data-scroll-target="#gpu에-텐서및-모델-넣기">3. GPU에 텐서(및 모델) 넣기</a></li>
  <li><a href="#텐서를-다시-cpu로-이동하기" id="toc-텐서를-다시-cpu로-이동하기" class="nav-link" data-scroll-target="#텐서를-다시-cpu로-이동하기">4. 텐서를 다시 CPU로 이동하기</a></li>
  </ul></li>
  <li><a href="#연습-문제" id="toc-연습-문제" class="nav-link" data-scroll-target="#연습-문제">연습 문제</a></li>
  <li><a href="#추가-학습-자료" id="toc-추가-학습-자료" class="nav-link" data-scroll-target="#추가-학습-자료">추가 학습 자료</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">00 - PyTorch 기초</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><a href="https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p>
<section id="pytorch란-무엇인가요" class="level2">
<h2 class="anchored" data-anchor-id="pytorch란-무엇인가요">PyTorch란 무엇인가요?</h2>
<p><a href="https://pytorch.org/">PyTorch</a>는 오픈 소스 머신러닝 및 딥러닝 프레임워크입니다.</p>
</section>
<section id="pytorch는-어디에-사용되나요" class="level2">
<h2 class="anchored" data-anchor-id="pytorch는-어디에-사용되나요">PyTorch는 어디에 사용되나요?</h2>
<p>PyTorch를 사용하면 파이썬 코드를 사용하여 데이터를 조작 및 처리하고 머신러닝 알고리즘을 작성할 수 있습니다.</p>
</section>
<section id="누가-pytorch를-사용하나요" class="level2">
<h2 class="anchored" data-anchor-id="누가-pytorch를-사용하나요">누가 PyTorch를 사용하나요?</h2>
<p>세계 최대 기술 기업 중 상당수가 <a href="https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/">Meta (Facebook)</a>, Tesla, Microsoft를 비롯하여 <a href="https://openai.com/blog/openai-pytorch/">OpenAI</a>와 같은 인공지능 연구 기업에서도 연구를 수행하고 제품에 머신러닝을 도입하기 위해 PyTorch를 사용합니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-being-used-across-research-and-industry.png" class="img-fluid figure-img"></p>
<figcaption>산업 및 연구 분야에서 사용되는 PyTorch</figcaption>
</figure>
</div>
<p>예를 들어, Andrej Karpathy(Tesla의 AI 책임자)는 Tesla가 자율 주행 컴퓨터 비전 모델을 구동하기 위해 PyTorch를 어떻게 사용하는지에 대해 여러 차례 강연(<a href="https://youtu.be/oBklltKXtDE">PyTorch DevCon 2019</a>, <a href="https://youtu.be/j0z4FweCy4M?t=2904">Tesla AI Day 2021</a>)을 한 바 있습니다.</p>
<p>PyTorch는 농업과 같은 다른 산업 분야에서도 <a href="https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1">트랙터의 컴퓨터 비전</a>을 구동하는 데 사용됩니다.</p>
</section>
<section id="왜-pytorch를-사용해야-하나요" class="level2">
<h2 class="anchored" data-anchor-id="왜-pytorch를-사용해야-하나요">왜 PyTorch를 사용해야 하나요?</h2>
<p>머신러닝 연구자들은 PyTorch 사용을 선호합니다. 2022년 2월 현재, PyTorch는 머신러닝 연구 논문과 그에 부수되는 코드 저장소를 추적하는 웹사이트인 <a href="https://paperswithcode.com/trends">Papers With Code에서 가장 많이 사용되는 딥러닝 프레임워크</a>입니다.</p>
<p>또한 PyTorch는 백그라운드에서 GPU 가속(코드 실행 속도 향상)과 같은 많은 것들을 처리해 줍니다.</p>
<p>따라서 여러분은 데이터 조작과 알고리즘 작성에 집중할 수 있으며, PyTorch가 이를 빠르게 실행되도록 보장합니다.</p>
<p>Tesla나 Meta (Facebook) 같은 기업들이 수백 개의 애플리케이션을 구동하고, 수천 대의 자동차를 운전하며, 수십억 명의 사람들에게 콘텐츠를 전달하기 위해 모델을 구축하는 데 PyTorch를 사용한다면, 개발 측면에서도 그 성능은 분명히 입증된 것입니다.</p>
</section>
<section id="이-모듈에서-다룰-내용" class="level2">
<h2 class="anchored" data-anchor-id="이-모듈에서-다룰-내용">이 모듈에서 다룰 내용</h2>
<p>이 과정은 여러 섹션(노트북)으로 나누어져 있습니다.</p>
<p>각 노트북은 PyTorch 내의 중요한 아이디어와 개념을 다룹니다.</p>
<p>이후의 노트북은 이전 노트북의 지식을 바탕으로 구성됩니다(번호는 00, 01, 02 순으로 시작하여 끝까지 이어집니다).</p>
<p>이 노트북은 머신러닝과 딥러닝의 기본 구성 요소인 <strong>텐서(tensor)</strong>를 다룹니다.</p>
<p>구체적으로 다음 내용을 다룹니다:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><strong>주제</strong></th>
<th><strong>내용</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>텐서 소개</strong></td>
<td>텐서는 모든 머신러닝 및 딥러닝의 기본 구성 요소입니다.</td>
</tr>
<tr class="even">
<td><strong>텐서 생성하기</strong></td>
<td>텐서는 거의 모든 종류의 데이터(이미지, 단어, 숫자 표)를 나타낼 수 있습니다.</td>
</tr>
<tr class="odd">
<td><strong>텐서에서 정보 가져오기</strong></td>
<td>정보를 텐서에 넣을 수 있다면, 다시 꺼내고 싶을 수도 있습니다.</td>
</tr>
<tr class="even">
<td><strong>텐서 조작하기</strong></td>
<td>머신러닝 알고리즘(신경망 등)은 더하기, 곱하기, 결합하기 등 다양한 방식으로 텐서를 조작하는 과정을 포함합니다.</td>
</tr>
<tr class="odd">
<td><strong>텐서 모양(shape) 다루기</strong></td>
<td>머신러닝에서 가장 흔한 문제 중 하나는 모양 불일치(잘못된 모양의 텐서를 다른 텐서와 혼합하려는 경우)를 다루는 것입니다.</td>
</tr>
<tr class="even">
<td><strong>텐서 인덱싱</strong></td>
<td>파이썬 리스트나 NumPy 배열에서 인덱싱을 해보셨다면 텐서와 매우 유사하지만, 훨씬 더 많은 차원을 가질 수 있습니다.</td>
</tr>
<tr class="odd">
<td><strong>PyTorch 텐서와 NumPy 혼합하기</strong></td>
<td>PyTorch는 텐서(<a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a>)를 다루고, NumPy는 배열(<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html"><code>np.ndarray</code></a>)을 선호합니다. 때로는 이 둘을 혼합하여 사용해야 할 때가 있습니다.</td>
</tr>
<tr class="even">
<td><strong>재현성</strong></td>
<td>머신러닝은 매우 실험적이며 작동을 위해 많은 <em>무작위성</em>을 사용하기 때문에, 때로는 그 <em>무작위성</em>이 너무 무작위적이지 않기를 원할 때가 있습니다.</td>
</tr>
<tr class="odd">
<td><strong>GPU에서 텐서 실행하기</strong></td>
<td>GPU(그래픽 처리 장치)는 코드를 더 빠르게 만들어주며, PyTorch는 GPU에서 코드를 쉽게 실행할 수 있게 해줍니다.</td>
</tr>
</tbody>
</table>
</section>
<section id="도움을-받을-수-있는-곳" class="level2">
<h2 class="anchored" data-anchor-id="도움을-받을-수-있는-곳">도움을 받을 수 있는 곳</h2>
<p>이 과정의 모든 자료는 <a href="https://github.com/mrdbourke/pytorch-deep-learning">GitHub</a>에 있습니다.</p>
<p>문제가 발생하면 해당 페이지의 <a href="https://github.com/mrdbourke/pytorch-deep-learning/discussions">Discussions 페이지</a>에서 질문할 수 있습니다.</p>
<p>또한 PyTorch와 관련된 모든 것에 대해 매우 도움이 되는 장소인 <a href="https://discuss.pytorch.org/">PyTorch 개발자 포럼</a>도 있습니다.</p>
</section>
<section id="pytorch-임포트하기" class="level2">
<h2 class="anchored" data-anchor-id="pytorch-임포트하기">PyTorch 임포트하기</h2>
<blockquote class="blockquote">
<p><strong>참고:</strong> 이 노트북의 코드를 실행하기 전에 <a href="https://pytorch.org/get-started/locally/">PyTorch 설치 단계</a>를 거쳐야 합니다.</p>
<p>하지만 <strong>Google Colab에서 실행 중이라면</strong>, 모든 것이 작동할 것입니다(Google Colab에는 PyTorch 및 기타 라이브러리가 이미 설치되어 있습니다).</p>
</blockquote>
<p>먼저 PyTorch를 임포트하고 사용 중인 버전을 확인해 보겠습니다.</p>
<div id="cell-3" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:35}}" data-outputid="f3141076-29bc-4600-c1c3-1586b1fe2292">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>torch.__version__</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>'1.10.0+cu111'</code></pre>
</div>
</div>
<p>좋습니다. PyTorch 1.10.0(2021년 12월 기준)이 설치되어 있는 것 같네요. 즉, 이 자료를 학습할 때 PyTorch 1.10.0과의 호환성이 가장 높을 것이며, 버전 번호가 그보다 훨씬 높으면 약간의 불일치를 느낄 수 있습니다.</p>
<p>문제가 발생하면 GitHub Discussions 페이지에 게시해 주세요.</p>
</section>
<section id="텐서-소개" class="level2">
<h2 class="anchored" data-anchor-id="텐서-소개">텐서 소개</h2>
<p>이제 PyTorch를 임포트했으니 텐서에 대해 배워볼 시간입니다.</p>
<p>텐서는 머신러닝의 기본 구성 요소입니다.</p>
<p>텐서의 역할은 데이터를 수치적으로 나타내는 것입니다.</p>
<p>예를 들어, 이미지를 <code>[3, 224, 224]</code> 모양의 텐서로 나타낼 수 있는데, 이는 <code>[색상_채널, 높이, 너비]</code>를 의미합니다. 즉, 이미지는 3개의 색상 채널(빨강, 초록, 파랑), 224픽셀의 높이 및 224픽셀의 너비를 가집니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png" class="img-fluid figure-img"></p>
<figcaption>입력 이미지에서 이미지의 텐서 표현으로 전환되는 예시. 이미지는 3개의 색상 채널뿐만 아니라 높이와 너비를 나타내는 숫자로 분해됩니다.</figcaption>
</figure>
</div>
<p>텐서 용어(텐서를 설명하는 데 사용되는 언어)로 말하면, 이 텐서는 <code>색상_채널</code>, <code>높이</code>, <code>너비</code>에 대해 세 개의 차원을 가집니다.</p>
<p>하지만 너무 앞서 나갔네요.</p>
<p>직접 코딩하며 텐서에 대해 더 자세히 알아봅시다.</p>
<section id="텐서-생성하기" class="level3">
<h3 class="anchored" data-anchor-id="텐서-생성하기">텐서 생성하기</h3>
<p>PyTorch는 텐서를 사랑합니다. 얼마나 사랑하느냐 하면 <a href="https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor"><code>torch.Tensor</code></a> 클래스만을 위한 전용 문서 페이지가 있을 정도입니다.</p>
<p>첫 번째 숙제는 <a href="https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor"><code>torch.Tensor</code> 문서</a>를 10분 동안 읽어보는 것입니다. 하지만 나중에 하셔도 됩니다.</p>
<p>코드를 작성해 봅시다.</p>
<p>가장 먼저 생성할 것은 <strong>스칼라(scalar)</strong>입니다.</p>
<p>스칼라는 단일 숫자이며, 텐서 용어로는 0차원 텐서입니다.</p>
<blockquote class="blockquote">
<p><strong>참고:</strong> 이것이 이 과정의 트렌드입니다. 구체적인 코드를 작성하는 데 집중할 것입니다. 하지만 종종 PyTorch 문서를 읽고 익숙해지는 연습을 과제로 내드릴 것입니다. 결국 이 과정을 마치고 나면 의심할 여지 없이 더 많은 것을 배우고 싶어질 것이기 때문입니다. 그리고 문서는 여러분이 매우 자주 찾게 될 장소입니다.</p>
</blockquote>
<div id="cell-7" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="0ac22bd2-16bc-4307-f312-31ae89d6c375">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 스칼라</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>scalar <span class="op">=</span> torch.tensor(<span class="dv">7</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>scalar</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>tensor(7)</code></pre>
</div>
</div>
<p>위의 출력이 <code>tensor(7)</code>로 나오는 것을 보셨나요?</p>
<p>이는 <code>scalar</code>가 단일 숫자이지만 <code>torch.Tensor</code> 유형임을 의미합니다.</p>
<p><code>ndim</code> 속성을 사용하여 텐서의 차원을 확인할 수 있습니다.</p>
<div id="cell-9" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="502a625e-ff3c-4fc4-b523-f7634ea82128">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>scalar.ndim</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>0</code></pre>
</div>
</div>
<p>텐서에서 숫자를 가져오고 싶다면 어떻게 해야 할까요?</p>
<p>즉, <code>torch.Tensor</code>를 파이썬 정수로 바꾸려면 말이죠.</p>
<p>그렇게 하려면 <code>item()</code> 메서드를 사용할 수 있습니다.</p>
<div id="cell-11" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1f6a7916-0c7c-403f-8ebd-875454a94470">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서 내의 파이썬 숫자 가져오기 (단일 요소 텐서에서만 작동함)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>scalar.item()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>7</code></pre>
</div>
</div>
<p>좋습니다. 이제 <strong>벡터(vector)</strong>를 살펴봅시다.</p>
<p>벡터는 단일 차원 텐서이지만 많은 숫자를 포함할 수 있습니다.</p>
<p>예를 들어, 집의 <code>[침실 수, 욕실 수]</code>를 설명하기 위해 벡터 <code>[3, 2]</code>를 가질 수 있습니다. 또는 집의 <code>[침실 수, 욕실 수, 주차 공간 수]</code>를 설명하기 위해 <code>[3, 2, 2]</code>를 가질 수 있습니다.</p>
<p>여기서 중요한 경향은 벡터가 나타낼 수 있는 것이 유연하다는 것입니다(텐서도 마찬가지입니다).</p>
<div id="cell-13" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e556ed2a-e58a-440f-b103-0f06c91bc75c">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 벡터</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>vector <span class="op">=</span> torch.tensor([<span class="dv">7</span>, <span class="dv">7</span>])</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>vector</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>tensor([7, 7])</code></pre>
</div>
</div>
<p>멋지네요. <code>vector</code>에는 제가 가장 좋아하는 숫자인 두 개의 7이 들어 있습니다.</p>
<p>차원이 몇 개일 것 같나요?</p>
<div id="cell-15" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2035bb26-0189-4b28-fa02-34220d44677f">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 벡터의 차원 수 확인</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>vector.ndim</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>1</code></pre>
</div>
</div>
<p>음, 이상하네요. <code>vector</code>에는 두 개의 숫자가 들어 있지만 차원은 하나뿐입니다.</p>
<p>비결을 하나 알려드리죠.</p>
<p>PyTorch에서 텐서의 차원 수는 바깥쪽 대괄호(<code>[</code>)의 개수로 알 수 있으며, 한쪽만 세면 됩니다.</p>
<p><code>vector</code>에는 대괄호가 몇 개 있나요?</p>
<p>텐서의 또 다른 중요한 개념은 <code>shape</code> 속성입니다. 모양(shape)은 내부의 요소가 어떻게 배열되어 있는지를 알려줍니다.</p>
<p><code>vector</code>의 모양을 확인해 봅시다.</p>
<div id="cell-17" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2a6e7ceb-7eb2-422b-b006-2c6e4825272f">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 벡터의 모양 확인</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>vector.shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>torch.Size([2])</code></pre>
</div>
</div>
<p>위의 결과는 <code>torch.Size([2])</code>를 반환하는데, 이는 우리 벡터의 모양이 <code>[2]</code>임을 의미합니다. 이는 대괄호 안에 두 개의 요소(<code>[7, 7]</code>)를 넣었기 때문입니다.</p>
<p>이제 <strong>행렬(matrix)</strong>을 살펴봅시다.</p>
<div id="cell-19" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="88fc63a7-4130-4c7a-a574-c61e85d2e99e">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 행렬</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>MATRIX <span class="op">=</span> torch.tensor([[<span class="dv">7</span>, <span class="dv">8</span>], </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>                       [<span class="dv">9</span>, <span class="dv">10</span>]])</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>MATRIX</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>tensor([[ 7,  8],
        [ 9, 10]])</code></pre>
</div>
</div>
<p>와! 더 많은 숫자네요! 행렬은 벡터만큼 유연하지만 차원이 하나 더 추가되었습니다.</p>
<div id="cell-21" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="636246b0-b109-472a-c6d5-8601a9e08654">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 차원 수 확인</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>MATRIX.ndim</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>2</code></pre>
</div>
</div>
<p><code>MATRIX</code>는 두 개의 차원을 가집니다(한쪽 면의 바깥쪽 대괄호 개수를 세어보셨나요?).</p>
<p>어떤 모양(<code>shape</code>)을 가질 것 같나요?</p>
<div id="cell-23" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f05ec0b6-0bc1-4381-9474-56cbe6c67139">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>MATRIX.shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>torch.Size([2, 2])</code></pre>
</div>
</div>
<p><code>MATRIX</code>가 깊이로 두 개의 요소, 너비로 두 개의 요소를 가지므로 <code>torch.Size([2, 2])</code>라는 출력을 얻습니다.</p>
<p>이제 <strong>텐서(tensor)</strong>를 만들어 볼까요?</p>
<div id="cell-25" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="4230e6bd-1844-4210-eea8-245bb8b8b265">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>TENSOR <span class="op">=</span> torch.tensor([[[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>],</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>                        [<span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">9</span>],</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>                        [<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">5</span>]]])</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>TENSOR</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor([[[1, 2, 3],
         [3, 6, 9],
         [2, 4, 5]]])</code></pre>
</div>
</div>
<p>우와! 정말 멋진 텐서네요.</p>
<p>텐서는 거의 무엇이든 나타낼 수 있다는 점을 강조하고 싶습니다.</p>
<p>방금 만든 것은 스테이크와 아몬드 버터 매장(제가 가장 좋아하는 두 음식입니다)의 판매 수치일 수도 있습니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_simple_tensor.png" class="img-fluid figure-img"></p>
<figcaption>요일, 스테이크 판매량, 아몬드 버터 판매량을 보여주는 Google 스프레드시트의 간단한 텐서</figcaption>
</figure>
</div>
<p>차원이 몇 개일 것 같나요? (힌트: 대괄호 세기 비결을 사용하세요)</p>
<div id="cell-27" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="7a45df1b-fc32-4cc5-e330-527c6ef7ba5d">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TENSOR의 차원 수 확인</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>TENSOR.ndim</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>3</code></pre>
</div>
</div>
<p>그 모양은 어떨까요?</p>
<div id="cell-29" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="d8ac706c-020b-4926-b145-d44e41f35e90">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TENSOR의 모양 확인</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>TENSOR.shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>torch.Size([1, 3, 3])</code></pre>
</div>
</div>
<p>좋습니다. <code>torch.Size([1, 3, 3])</code>이 출력되네요.</p>
<p>차원은 바깥쪽에서 안쪽 순서입니다.</p>
<p>즉, 3x3인 차원이 1개 있다는 뜻입니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png" class="img-fluid figure-img"></p>
<figcaption>다양한 텐서 차원의 예시</figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p><strong>참고:</strong> <code>scalar</code>와 <code>vector</code>에는 소문자를 사용하고 <code>MATRIX</code>와 <code>TENSOR</code>에는 대문자를 사용한 것을 눈치채셨을 것입니다. 이는 의도적인 것입니다. 실제로 스칼라와 벡터는 <code>y</code>나 <code>a</code>와 같은 소문자로 표시되는 경우가 많습니다. 그리고 행렬과 텐서는 <code>X</code>나 <code>W</code>와 같은 대문자로 표시됩니다.</p>
<p>또한 행렬(matrix)과 텐서(tensor)라는 이름이 혼용되어 사용되는 것을 볼 수 있습니다. 이는 흔한 일입니다. PyTorch에서는 종종 <code>torch.Tensor</code>를 다루기 때문입니다(그래서 텐서라는 이름이 붙었습니다). 하지만 내부 내용의 모양과 차원에 따라 실제로 무엇인지가 결정됩니다.</p>
</blockquote>
<p>요약해 봅시다.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>이름</th>
<th>무엇인가요?</th>
<th>차원 수</th>
<th>소문자 또는 대문자 (보통/예시)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>스칼라(scalar)</strong></td>
<td>단일 숫자</td>
<td>0</td>
<td>소문자 (<code>a</code>)</td>
</tr>
<tr class="even">
<td><strong>벡터(vector)</strong></td>
<td>방향이 있는 숫자(예: 방향이 있는 풍속)이지만 다른 많은 숫자도 가질 수 있음</td>
<td>1</td>
<td>소문자 (<code>y</code>)</td>
</tr>
<tr class="odd">
<td><strong>행렬(matrix)</strong></td>
<td>숫자의 2차원 배열</td>
<td>2</td>
<td>대문자 (<code>Q</code>)</td>
</tr>
<tr class="even">
<td><strong>텐서(tensor)</strong></td>
<td>숫자의 n차원 배열</td>
<td>어떤 수든 가능, 0차원 텐서는 스칼라, 1차원 텐서는 벡터</td>
<td>대문자 (<code>X</code>)</td>
</tr>
</tbody>
</table>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png" class="img-fluid figure-img"></p>
<figcaption>스칼라 벡터 행렬 텐서의 모습</figcaption>
</figure>
</div>
</section>
<section id="무작위-텐서" class="level3">
<h3 class="anchored" data-anchor-id="무작위-텐서">무작위 텐서</h3>
<p>우리는 텐서가 어떤 형태의 데이터를 나타낸다는 것을 확인했습니다.</p>
<p>그리고 신경망과 같은 머신러닝 모델은 텐서 내의 패턴을 조사하고 찾기 위해 조작합니다.</p>
<p>하지만 PyTorch로 머신러닝 모델을 구축할 때 (우리가 했던 것처럼) 손으로 텐서를 직접 만드는 경우는 드뭅니다.</p>
<p>대신, 머신러닝 모델은 종종 대량의 무작위 숫자 텐서로 시작하여 데이터를 처리하면서 이러한 무작위 숫자를 조정하여 데이터를 더 잘 나타내도록 합니다.</p>
<p>본질적으로:</p>
<p><code>무작위 숫자로 시작 -&gt; 데이터 확인 -&gt; 무작위 숫자 업데이트 -&gt; 데이터 확인 -&gt; 무작위 숫자 업데이트...</code></p>
<p>데이터 과학자로서 여러분은 머신러닝 모델이 무작위 숫자를 어떻게 시작(초기화)하고, 데이터를 어떻게 확인(표현)하며, 어떻게 업데이트(최적화)할지 정의할 수 있습니다.</p>
<p>나중에 이러한 단계를 직접 실습해 볼 것입니다.</p>
<p>지금은 무작위 숫자로 텐서를 생성하는 방법을 알아봅시다.</p>
<p><a href="https://pytorch.org/docs/stable/generated/torch.rand.html"><code>torch.rand()</code></a>를 사용하고 <code>size</code> 매개변수를 전달하여 이를 수행할 수 있습니다.</p>
<div id="cell-32" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2680d44b-e31c-4ab1-d5b1-c0cd76706a0d">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 크기가 (3, 4)인 무작위 텐서 생성</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>random_tensor <span class="op">=</span> torch.rand(size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">4</span>))</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>random_tensor, random_tensor.dtype</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>(tensor([[0.4090, 0.2527, 0.8699, 0.2002],
         [0.8421, 0.1428, 0.1431, 0.0111],
         [0.2281, 0.0345, 0.6734, 0.3866]]), torch.float32)</code></pre>
</div>
</div>
<p><code>torch.rand()</code>의 유연성은 <code>size</code>를 우리가 원하는 대로 조정할 수 있다는 점입니다.</p>
<p>예를 들어, 일반적인 이미지 모양인 <code>[224, 224, 3]</code> (<code>[높이, 너비, 색상_채널]</code>)의 무작위 텐서를 원한다고 가정해 봅시다.</p>
<div id="cell-34" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="8346b853-0b1e-481a-d9ee-a410ee21bab0">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 크기가 (224, 224, 3)인 무작위 텐서 생성</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>random_image_size_tensor <span class="op">=</span> torch.rand(size<span class="op">=</span>(<span class="dv">224</span>, <span class="dv">224</span>, <span class="dv">3</span>))</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>random_image_size_tensor.shape, random_image_size_tensor.ndim</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>(torch.Size([224, 224, 3]), 3)</code></pre>
</div>
</div>
</section>
<section id="과-1" class="level3">
<h3 class="anchored" data-anchor-id="과-1">0과 1</h3>
<p>때로는 텐서를 0이나 1로 채우고 싶을 때가 있습니다.</p>
<p>이는 마스킹(masking) 작업에서 많이 발생합니다(예: 한 텐서의 일부 값을 0으로 마스킹하여 모델이 학습하지 않도록 알림).</p>
<p><a href="https://pytorch.org/docs/stable/generated/torch.zeros.html"><code>torch.zeros()</code></a>를 사용하여 0으로 가득 찬 텐서를 만들어 봅시다.</p>
<p>여기서도 <code>size</code> 매개변수가 사용됩니다.</p>
<div id="cell-36" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="9c8ec87f-d8c9-4751-a13e-6a5e986daaa9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 모두 0인 텐서 생성</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>zeros <span class="op">=</span> torch.zeros(size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">4</span>))</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>zeros, zeros.dtype</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>(tensor([[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]), torch.float32)</code></pre>
</div>
</div>
<p><a href="https://pytorch.org/docs/stable/generated/torch.ones.html"><code>torch.ones()</code></a>를 대신 사용하여 모두 1인 텐서를 만드는 것도 동일하게 수행할 수 있습니다.</p>
<div id="cell-38" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3f45b0b8-7f65-423d-c664-f5b5f7866fd2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 모두 1인 텐서 생성</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>ones <span class="op">=</span> torch.ones(size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">4</span>))</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>ones, ones.dtype</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>(tensor([[1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.]]), torch.float32)</code></pre>
</div>
</div>
</section>
<section id="범위-및-유사-텐서-생성" class="level3">
<h3 class="anchored" data-anchor-id="범위-및-유사-텐서-생성">범위 및 유사 텐서 생성</h3>
<p>때로는 1에서 10 또는 0에서 100과 같은 숫자 범위가 필요할 수 있습니다.</p>
<p><code>torch.arange(start, end, step)</code>을 사용하여 이를 수행할 수 있습니다.</p>
<p>여기서: * <code>start</code> = 범위의 시작 (예: 0) * <code>end</code> = 범위의 끝 (예: 10) * <code>step</code> = 각 값 사이의 간격 (예: 1)</p>
<blockquote class="blockquote">
<p><strong>참고:</strong> 파이썬에서는 <code>range()</code>를 사용하여 범위를 생성할 수 있습니다. 하지만 PyTorch에서 <code>torch.range()</code>는 더 이상 사용되지 않으며(deprecated) 미래에 오류가 발생할 수 있습니다.</p>
</blockquote>
<div id="cell-40" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2a6f0c08-052e-4b36-b4eb-6a537239026f">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># torch.arange() 사용, torch.range()는 권장되지 않음</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>zero_to_ten_deprecated <span class="op">=</span> torch.<span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">10</span>) <span class="co"># 참고: 미래에 오류가 발생할 수 있음</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 0에서 10까지의 값 범위 생성</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>zero_to_ten <span class="op">=</span> torch.arange(start<span class="op">=</span><span class="dv">0</span>, end<span class="op">=</span><span class="dv">10</span>, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>zero_to_ten</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  </code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</code></pre>
</div>
</div>
<p>때로는 다른 텐서와 동일한 모양을 가진 특정 유형의 텐서가 필요할 수 있습니다.</p>
<p>예를 들어, 이전 텐서와 모양이 같은 모두 0인 텐서가 있을 수 있습니다.</p>
<p>그렇게 하려면 각각 <code>input</code>과 동일한 모양의 0 또는 1로 채워진 텐서를 반환하는 <a href="https://pytorch.org/docs/stable/generated/torch.zeros_like.html"><code>torch.zeros_like(input)</code></a> 또는 <a href="https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html"><code>torch.ones_like(input)</code></a>을 사용할 수 있습니다.</p>
<div id="cell-42" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="096b2f8e-8c21-4ace-97b9-c36b92b2fe77">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 다른 텐서와 유사한 0으로 된 텐서 생성 가능</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>ten_zeros <span class="op">=</span> torch.zeros_like(<span class="bu">input</span><span class="op">=</span>zero_to_ten) <span class="co"># 같은 모양을 가짐</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>ten_zeros</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])</code></pre>
</div>
</div>
</section>
<section id="텐서-데이터-타입" class="level3">
<h3 class="anchored" data-anchor-id="텐서-데이터-타입">텐서 데이터 타입</h3>
<p>PyTorch에서는 다양한 <a href="https://pytorch.org/docs/stable/tensors.html#data-types">텐서 데이터 타입</a>을 사용할 수 있습니다.</p>
<p>어떤 것은 CPU에 특화되어 있고 어떤 것은 GPU에 더 적합합니다.</p>
<p>어떤 것이 무엇인지 익히는 데는 시간이 좀 걸릴 수 있습니다.</p>
<p>일반적으로 어디서나 <code>torch.cuda</code>가 보이면, 해당 텐서는 GPU에서 사용되고 있는 것입니다(Nvidia GPU는 CUDA라는 컴퓨팅 툴킷을 사용하기 때문입니다).</p>
<p>가장 일반적인 유형(및 일반적으로 기본값)은 <code>torch.float32</code> 또는 <code>torch.float</code>입니다.</p>
<p>이를 “32비트 부동 소수점”이라고 합니다.</p>
<p>하지만 16비트 부동 소수점(<code>torch.float16</code> 또는 <code>torch.half</code>)과 64비트 부동 소수점(<code>torch.float64</code> 또는 <code>torch.double</code>)도 있습니다.</p>
<p>더 복잡하게는 8비트, 16비트, 32비트, 64비트 정수도 있습니다.</p>
<p>그리고 더 많이요!</p>
<blockquote class="blockquote">
<p><strong>참고:</strong> 정수(integer)는 <code>7</code>과 같이 딱 떨어지는 숫자이고, 부동 소수점(float)은 <code>7.0</code>과 같이 소수점이 있습니다.</p>
</blockquote>
<p>이 모든 이유가 있는 것은 <strong>컴퓨팅의 정밀도(precision)</strong> 때문입니다.</p>
<p>정밀도는 숫자를 설명하는 데 사용되는 세부 정보의 양입니다.</p>
<p>정밀도 값(8, 16, 32)이 높을수록 숫자를 표현하는 데 더 많은 세부 정보와 데이터가 사용됩니다.</p>
<p>이는 딥러닝과 수치 컴퓨팅에서 중요한데, 수많은 연산을 수행하기 때문에 계산해야 할 세부 정보가 많을수록 더 많은 컴퓨팅 파워를 사용해야 하기 때문입니다.</p>
<p>따라서 정밀도가 낮은 데이터 타입은 일반적으로 계산 속도가 빠르지만 정확도와 같은 평가 지표에서 약간의 성능 손실이 발생합니다(계산은 빠르지만 정확도는 떨어짐).</p>
<blockquote class="blockquote">
<p><strong>리소스:</strong> * 사용 가능한 모든 텐서 데이터 타입 목록은 <a href="https://pytorch.org/docs/stable/tensors.html#data-types">PyTorch 문서</a>를 참조하세요. * 컴퓨팅에서의 정밀도에 대한 개요는 <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">Wikipedia 페이지</a>를 읽어보세요.</p>
</blockquote>
<p>특정 데이터 타입으로 텐서를 생성하는 방법을 알아봅시다. <code>dtype</code> 매개변수를 사용하여 수행할 수 있습니다.</p>
<div id="cell-44" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="61070939-8c52-4ac6-bed7-e64b3ce24615">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서의 기본 데이터 타입은 float32</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>float_32_tensor <span class="op">=</span> torch.tensor([<span class="fl">3.0</span>, <span class="fl">6.0</span>, <span class="fl">9.0</span>],</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>                               dtype<span class="op">=</span><span class="va">None</span>, <span class="co"># 기본값은 None이며, torch.float32 또는 전달된 데이터 타입으로 설정됨</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>                               device<span class="op">=</span><span class="va">None</span>, <span class="co"># 기본값은 None이며, 기본 텐서 유형을 사용함</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>                               requires_grad<span class="op">=</span><span class="va">False</span>) <span class="co"># True이면 텐서에서 수행된 연산이 기록됨</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>(torch.Size([3]), torch.float32, device(type='cpu'))</code></pre>
</div>
</div>
<p>모양 문제(텐서 모양이 일치하지 않음) 외에도 PyTorch에서 겪게 될 가장 흔한 두 가지 문제는 데이터 타입과 장치(device) 문제입니다.</p>
<p>예를 들어, 텐서 중 하나는 <code>torch.float32</code>이고 다른 하나는 <code>torch.float16</code>인 경우입니다(PyTorch는 종종 텐서가 동일한 형식인 것을 선호합니다).</p>
<p>또는 텐서 중 하나는 CPU에 있고 다른 하나는 GPU에 있는 경우입니다(PyTorch는 텐서 간의 계산이 동일한 장치에서 수행되는 것을 선호합니다).</p>
<p>나중에 이 장치에 대한 이야기를 더 자세히 다룰 것입니다.</p>
<p>지금은 <code>dtype=torch.float16</code>인 텐서를 만들어 보겠습니다.</p>
<div id="cell-46" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="cbac29d9-3371-4fe1-b47c-3af4623b5fbf">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>float_16_tensor <span class="op">=</span> torch.tensor([<span class="fl">3.0</span>, <span class="fl">6.0</span>, <span class="fl">9.0</span>],</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>                               dtype<span class="op">=</span>torch.float16) <span class="co"># torch.half도 작동함</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>float_16_tensor.dtype</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>torch.float16</code></pre>
</div>
</div>
</section>
</section>
<section id="텐서에서-정보-가져오기" class="level2">
<h2 class="anchored" data-anchor-id="텐서에서-정보-가져오기">텐서에서 정보 가져오기</h2>
<p>텐서를 생성한 후에는 (또는 다른 사람이나 PyTorch 모듈이 대신 생성한 후에는) 텐서에서 정보를 얻고 싶을 수 있습니다.</p>
<p>이전에 살펴보았지만, 텐서에 대해 알아내고 싶은 가장 일반적인 세 가지 속성은 다음과 같습니다. * <code>shape</code> - 텐서의 모양은 무엇인가? (일부 연산에는 특정 모양 규칙이 필요함) * <code>dtype</code> - 텐서 내의 요소는 어떤 데이터 타입으로 저장되어 있는가? * <code>device</code> - 텐서는 어떤 장치에 저장되어 있는가? (보통 GPU 또는 CPU)</p>
<p>무작위 텐서를 생성하고 세부 정보를 알아봅시다.</p>
<div id="cell-48" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="86045713-ab36-4c8e-840c-e788f80c5266">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서 생성</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>some_tensor <span class="op">=</span> torch.rand(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 세부 정보 확인</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(some_tensor)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"텐서의 모양: </span><span class="sc">{</span>some_tensor<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"텐서의 데이터 타입: </span><span class="sc">{</span>some_tensor<span class="sc">.</span>dtype<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"텐서가 저장된 장치: </span><span class="sc">{</span>some_tensor<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>) <span class="co"># 기본값은 CPU</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0.7799, 0.8140, 0.0893, 0.2062],
        [0.7525, 0.3845, 0.8207, 0.4587],
        [0.9277, 0.8166, 0.9052, 0.0953]])
Shape of tensor: torch.Size([3, 4])
Datatype of tensor: torch.float32
Device tensor is stored on: cpu</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>참고:</strong> PyTorch에서 문제가 발생하면 위의 세 가지 속성 중 하나와 관련된 경우가 매우 많습니다. 따라서 오류 메시지가 나타나면 스스로에게 “뭐, 뭐, 어디”라는 짧은 노래를 불러보세요. * “<em>내 텐서의 모양은 뭐고? 데이터 타입은 뭐고, 어디에 저장되어 있지? 모양은 뭐고, 타입은 뭐고, 어디 어디 어디</em>”</p>
</blockquote>
</section>
<section id="텐서-조작-텐서-연산" class="level2">
<h2 class="anchored" data-anchor-id="텐서-조작-텐서-연산">텐서 조작 (텐서 연산)</h2>
<p>딥러닝에서 데이터(이미지, 텍스트, 비디오, 오디오, 단백질 구조 등)는 텐서로 표현됩니다.</p>
<p>모델은 해당 텐서를 조사하고 입력 데이터의 패턴 표현을 생성하기 위해 텐서에 대해 일련의 연산(수백만 개 이상일 수 있음)을 수행하여 학습합니다.</p>
<p>이러한 연산은 종종 다음과 같은 멋진 춤과 같습니다. * 덧셈 * 뺄셈 * 곱셈 (요소별) * 나눗셈 * 행렬 곱셈</p>
<p>그리고 이것이 전부입니다. 물론 여기저기 몇 가지 더 있지만 이것이 신경망의 기본 구성 요소입니다.</p>
<p>이러한 구성 요소를 올바른 방식으로 쌓으면 (마치 레고처럼!) 가장 정교한 신경망을 만들 수 있습니다.</p>
<section id="기본-연산" class="level3">
<h3 class="anchored" data-anchor-id="기본-연산">기본 연산</h3>
<p>덧셈(<code>+</code>), 뺄셈(<code>-</code>), 곱셈(<code>*</code>)과 같은 몇 가지 기본적인 연산부터 시작하겠습니다.</p>
<p>여러분이 생각하는 대로 작동합니다.</p>
<div id="cell-52" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ab30f13e-fc67-4ae4-c5ce-1006410dba07">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 값의 텐서를 생성하고 숫자를 더하기</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">+</span> <span class="dv">10</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([11, 12, 13])</code></pre>
</div>
</div>
<div id="cell-53" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ce7d2296-881f-4eb3-802e-fd12bc25d6ea">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 10을 곱하기</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">*</span> <span class="dv">10</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([10, 20, 30])</code></pre>
</div>
</div>
<p>위의 텐서 값이 <code>tensor([110, 120, 130])</code>으로 끝나지 않은 점에 유의하세요. 이는 텐서 내부의 값이 재할당되지 않는 한 변경되지 않기 때문입니다.</p>
<div id="cell-55" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="57cae862-c145-4681-d74b-fe6d77f2125a">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서는 재할당되지 않는 한 변경되지 않음</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>tensor</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor([1, 2, 3])</code></pre>
</div>
</div>
<p>숫자를 빼보고 이번에는 <code>tensor</code> 변수를 재할당해 보겠습니다.</p>
<div id="cell-57" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="14d6771d-eb57-4b11-88a7-b1bb308ddc6e">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 빼고 재할당하기</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> tensor <span class="op">-</span> <span class="dv">10</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>tensor</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>tensor([-9, -8, -7])</code></pre>
</div>
</div>
<div id="cell-58" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3536ea54-a056-444c-cd5d-6d438ddda965">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 더하고 재할당하기</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> tensor <span class="op">+</span> <span class="dv">10</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>tensor</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([1, 2, 3])</code></pre>
</div>
</div>
<p>PyTorch에는 기본 연산을 수행하기 위한 <a href="https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul"><code>torch.mul()</code></a>(곱셈의 약자) 및 <a href="https://pytorch.org/docs/stable/generated/torch.add.html"><code>torch.add()</code></a>와 같은 많은 내장 함수도 있습니다.</p>
<div id="cell-60" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3a5bf687-cf24-4224-9e76-975f84638ca8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># torch 함수를 사용할 수도 있음</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>torch.multiply(tensor, <span class="dv">10</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>tensor([10, 20, 30])</code></pre>
</div>
</div>
<div id="cell-61" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f04cafd9-eaea-4254-df1a-5ab3b524d74e">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 원본 텐서는 여전히 변경되지 않음</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>tensor</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>tensor([1, 2, 3])</code></pre>
</div>
</div>
<p>하지만 <code>torch.mul()</code> 대신 <code>*</code>와 같은 연산자 기호를 사용하는 것이 더 일반적입니다.</p>
<div id="cell-63" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="0137caab-5ea1-4d95-f4c5-a0baa0fd652d">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 요소별 곱셈 (각 요소는 해당 위치의 요소와 곱해짐, 인덱스 0-&gt;0, 1-&gt;1, 2-&gt;2)</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor, <span class="st">"*"</span>, tensor)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"결과:"</span>, tensor <span class="op">*</span> tensor)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([1, 2, 3]) * tensor([1, 2, 3])
Equals: tensor([1, 4, 9])</code></pre>
</div>
</div>
</section>
<section id="행렬-곱셈-matrix-multiplication" class="level3">
<h3 class="anchored" data-anchor-id="행렬-곱셈-matrix-multiplication">행렬 곱셈 (Matrix Multiplication)</h3>
<p>머신러닝 및 딥러닝 알고리즘(신경망 등)에서 가장 흔한 연산 중 하나는 <a href="https://www.mathsisfun.com/algebra/matrix-multiplying.html">행렬 곱셈</a>입니다.</p>
<p>PyTorch는 <a href="https://pytorch.org/docs/stable/generated/torch.matmul.html"><code>torch.matmul()</code></a> 메서드에 행렬 곱셈 기능을 구현합니다.</p>
<p>기억해야 할 행렬 곱셈의 주요 규칙 두 가지는 다음과 같습니다. 1. <strong>내부 차원(inner dimensions)</strong>이 일치해야 합니다. * <code>(3, 2) @ (3, 2)</code>는 작동하지 않음 * <code>(2, 3) @ (3, 2)</code>는 작동함 * <code>(3, 2) @ (2, 3)</code>은 작동함 2. 결과 행렬은 <strong>외부 차원(outer dimensions)</strong>의 모양을 가집니다. * <code>(2, 3) @ (3, 2)</code> -&gt; <code>(2, 2)</code> * <code>(3, 2) @ (2, 3)</code> -&gt; <code>(3, 3)</code></p>
<blockquote class="blockquote">
<p><strong>참고:</strong> 파이썬에서 “<code>@</code>”는 행렬 곱셈 기호입니다.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>리소스:</strong> <code>torch.matmul()</code>을 사용하는 행렬 곱셈의 모든 규칙은 <a href="https://pytorch.org/docs/stable/generated/torch.matmul.html">PyTorch 문서</a>에서 확인할 수 있습니다.</p>
</blockquote>
<p>텐서를 생성하고 요소별 곱셈과 행렬 곱셈을 수행해 보겠습니다.</p>
<div id="cell-65" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="44032bf9-c1f7-42fc-c842-dbe7a5c1221a">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>tensor.shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>torch.Size([3])</code></pre>
</div>
</div>
<p>요소별 곱셈과 행렬 곱셈의 차이는 값의 합산입니다.</p>
<p>값이 <code>[1, 2, 3]</code>인 <code>tensor</code> 변수의 경우:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>연산</th>
<th>계산</th>
<th>코드</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>요소별 곱셈</strong></td>
<td><code>[1*1, 2*2, 3*3]</code> = <code>[1, 4, 9]</code></td>
<td><code>tensor * tensor</code></td>
</tr>
<tr class="even">
<td><strong>행렬 곱셈</strong></td>
<td><code>[1*1 + 2*2 + 3*3]</code> = <code>[14]</code></td>
<td><code>tensor.matmul(tensor)</code></td>
</tr>
</tbody>
</table>
<div id="cell-67" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="18a630ce-bb56-4c40-81b4-9fdbb2ed7a4f">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 요소별 행렬 곱셈</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">*</span> tensor</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>tensor([1, 4, 9])</code></pre>
</div>
</div>
<div id="cell-68" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="cf623247-8f1b-49f1-e788-16da3ed1e59c">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 행렬 곱셈</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>torch.matmul(tensor, tensor)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>tensor(14)</code></pre>
</div>
</div>
<div id="cell-69" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="a09af00f-277b-479e-b0a2-ad6311ee5413">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 권장되지는 않지만 행렬 곱셈에 "@" 기호를 사용할 수도 있음</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">@</span> tensor</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>tensor(14)</code></pre>
</div>
</div>
<p>행렬 곱셈을 수동으로 할 수도 있지만 권장하지 않습니다.</p>
<p>내장된 <code>torch.matmul()</code> 메서드가 더 빠릅니다.</p>
<div id="cell-71" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="8bcad8a2-c900-4966-e13c-ff2cc02b9207">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 수동 행렬 곱셈</span></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="co"># (for 루프를 사용한 연산은 계산 비용이 많이 들므로 가급적 피하세요)</span></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>value <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(tensor)):</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>  value <span class="op">+=</span> tensor[i] <span class="op">*</span> tensor[i]</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>value</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 146 µs, sys: 38 µs, total: 184 µs
Wall time: 227 µs</code></pre>
</div>
</div>
<div id="cell-72" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="fce58235-5c09-49ec-f34b-a90e5640281e">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>torch.matmul(tensor, tensor)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 27 µs, sys: 7 µs, total: 34 µs
Wall time: 36.7 µs</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor(14)</code></pre>
</div>
</div>
</section>
</section>
<section id="딥러닝에서-가장-흔한-오류-중-하나-모양-오류" class="level2">
<h2 class="anchored" data-anchor-id="딥러닝에서-가장-흔한-오류-중-하나-모양-오류">딥러닝에서 가장 흔한 오류 중 하나 (모양 오류)</h2>
<p>딥러닝의 대부분은 행렬을 곱하고 연산을 수행하는 것이고, 행렬에는 결합할 수 있는 모양과 크기에 대한 엄격한 규칙이 있기 때문에 딥러닝에서 겪게 될 가장 흔한 오류 중 하나는 모양 불일치(shape mismatch)입니다.</p>
<div id="cell-74" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:204}}" data-outputid="20f6c65b-86f4-4903-d253-f6cbf0583934">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 모양이 올바른 방식이어야 함</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>tensor_A <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>],</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">3</span>, <span class="dv">4</span>],</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">5</span>, <span class="dv">6</span>]], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>tensor_B <span class="op">=</span> torch.tensor([[<span class="dv">7</span>, <span class="dv">10</span>],</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">8</span>, <span class="dv">11</span>], </span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">9</span>, <span class="dv">12</span>]], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>torch.matmul(tensor_A, tensor_B) <span class="co"># (오류 발생)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-37-aceec990e652&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">      8</span>                          [9, 12]], dtype=torch.float32)
<span class="ansi-green-fg ansi-bold">      9</span> 
<span class="ansi-green-fg">---&gt; 10</span><span class="ansi-red-fg"> </span>torch<span class="ansi-blue-fg">.</span>matmul<span class="ansi-blue-fg">(</span>tensor_A<span class="ansi-blue-fg">,</span> tensor_B<span class="ansi-blue-fg">)</span> <span class="ansi-red-fg"># (오류 발생)</span>

<span class="ansi-red-fg">RuntimeError</span>: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)</pre>
</div>
</div>
</div>
<p><code>tensor_A</code>와 <code>tensor_B</code> 사이의 내부 차원을 일치시켜 행렬 곱셈이 작동하도록 만들 수 있습니다.</p>
<p>이를 수행하는 방법 중 하나는 <strong>전치(transpose)</strong>(주어진 텐서의 차원을 전환함)를 사용하는 것입니다.</p>
<p>PyTorch에서는 다음 중 하나를 사용하여 전치를 수행할 수 있습니다. * <code>torch.transpose(input, dim0, dim1)</code> - 여기서 <code>input</code>은 전치할 텐서이고 <code>dim0</code>과 <code>dim1</code>은 교체할 차원입니다. * <code>tensor.T</code> - 여기서 <code>tensor</code>는 전치할 텐서입니다.</p>
<p>후자를 시도해 봅시다.</p>
<div id="cell-76" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e48bbf0c-8008-434e-d372-caa658b2f36b">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor_A와 tensor_B 확인</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_A)</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_B)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1., 2.],
        [3., 4.],
        [5., 6.]])
tensor([[ 7., 10.],
        [ 8., 11.],
        [ 9., 12.]])</code></pre>
</div>
</div>
<div id="cell-77" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1bd2e85b-ea4d-4948-c408-8eb46ef3534c">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor_A와 tensor_B.T 확인</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_A)</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_B.T)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1., 2.],
        [3., 4.],
        [5., 6.]])
tensor([[ 7.,  8.,  9.],
        [10., 11., 12.]])</code></pre>
</div>
</div>
<div id="cell-78" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="0b32c7f1-556e-45d4-de22-388419e93dc2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor_B가 전치되었을 때 연산이 작동함</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"원본 모양: tensor_A = </span><span class="sc">{</span>tensor_A<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, tensor_B = </span><span class="sc">{</span>tensor_B<span class="sc">.</span>shape<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"새로운 모양: tensor_A = </span><span class="sc">{</span>tensor_A<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (이전과 동일), tensor_B.T = </span><span class="sc">{</span>tensor_B<span class="sc">.</span>T<span class="sc">.</span>shape<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"곱셈 수행: </span><span class="sc">{</span>tensor_A<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> * </span><span class="sc">{</span>tensor_B<span class="sc">.</span>T<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> &lt;- 내부 차원 일치</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"출력:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> torch.matmul(tensor_A, tensor_B.T)</span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output) </span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">출력 모양: </span><span class="sc">{</span>output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])

New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])

Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) &lt;- inner dimensions match

Output:

tensor([[ 27.,  30.,  33.],
        [ 61.,  68.,  75.],
        [ 95., 106., 117.]])

Output shape: torch.Size([3, 3])</code></pre>
</div>
</div>
<p><code>torch.matmul()</code>의 줄임말인 <a href="https://pytorch.org/docs/stable/generated/torch.mm.html"><code>torch.mm()</code></a>을 사용할 수도 있습니다.</p>
<div id="cell-80" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2c501972-20bf-4a83-ad4a-b5f1b2424097">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># torch.mm은 matmul의 줄임말</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>torch.mm(tensor_A, tensor_B.T)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>tensor([[ 27.,  30.,  33.],
        [ 61.,  68.,  75.],
        [ 95., 106., 117.]])</code></pre>
</div>
</div>
<p>전치가 없으면 행렬 곱셈의 규칙이 충족되지 않고 위와 같은 오류가 발생합니다.</p>
<p>시각화 자료는 어떨까요?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-matrix-multiply-crop.gif" class="img-fluid figure-img"></p>
<figcaption>행렬 곱셈의 시각적 데모</figcaption>
</figure>
</div>
<p>http://matrixmultiplication.xyz/ 에서 이와 같은 자신만의 행렬 곱셈 시각화 자료를 만들 수 있습니다.</p>
<blockquote class="blockquote">
<p><strong>참고:</strong> 이와 같은 행렬 곱셈은 두 행렬의 <a href="https://www.mathsisfun.com/algebra/vectors-dot-product.html"><strong>내적(dot product)</strong></a>이라고도 합니다.</p>
</blockquote>
<p>신경망은 행렬 곱셈과 내적으로 가득 차 있습니다.</p>
<p>피드포워드 레이어(feed-forward layer) 또는 완전 연결 레이어(fully connected layer)라고도 하는 <a href="https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html"><code>torch.nn.Linear()</code></a> 모듈(나중에 실제 작동하는 모습을 볼 것입니다)은 입력 <code>x</code>와 가중치 행렬 <code>A</code> 사이의 행렬 곱셈을 구현합니다.</p>
<p><span class="math display">\[
y = x\cdot{A^T} + b
\]</span></p>
<p>여기서: * <code>x</code>는 레이어의 입력입니다(딥러닝은 <code>torch.nn.Linear()</code> 및 기타 레이어를 서로 겹쳐 쌓은 것입니다). * <code>A</code>는 레이어에 의해 생성된 가중치 행렬입니다. 이것은 무작위 숫자로 시작하여 신경망이 데이터의 패턴을 더 잘 나타내도록 학습함에 따라 조정됩니다(가중치 행렬이 전치되기 때문에 “<code>T</code>”에 유의하세요). * <strong>참고:</strong> 가중치 행렬을 나타내기 위해 <code>W</code>나 <code>X</code>와 같은 다른 문자가 사용되는 것을 종종 볼 수 있습니다. * <code>b</code>는 가중치와 입력을 약간 오프셋하는 데 사용되는 편향(bias) 용어입니다. * <code>y</code>는 출력입니다(입력에서 패턴을 발견하기를 바라며 입력을 조작한 결과입니다).</p>
<p>이것은 선형 함수(고등학교나 다른 곳에서 <span class="math inline">\(y = mx+b\)</span>와 같은 것을 본 적이 있을 것입니다)이며, 직선을 그리는 데 사용될 수 있습니다!</p>
<p>선형 레이어를 가지고 놀아봅시다.</p>
<p>아래에서 <code>in_features</code>와 <code>out_features</code>의 값을 변경하고 어떤 일이 일어나는지 확인해 보세요.</p>
<p>모양과 관련하여 눈에 띄는 점이 있나요?</p>
<div id="cell-83" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="768f75d2-c978-4df3-e18a-4684d46bdfa9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 선형 레이어는 무작위 가중치 행렬로 시작하므로 재현 가능하게 만듭시다(나중에 자세히 설명)</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 이것은 행렬 곱셈을 사용함</span></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>linear <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">2</span>, <span class="co"># in_features = 입력의 내부 차원과 일치해야 함</span></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>                         out_features<span class="op">=</span><span class="dv">6</span>) <span class="co"># out_features = 출력 값을 설명함</span></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tensor_A</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> linear(x)</span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"입력 모양: </span><span class="sc">{</span>x<span class="sc">.</span>shape<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"출력:</span><span class="ch">\n</span><span class="sc">{</span>output<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">출력 모양: </span><span class="sc">{</span>output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Input shape: torch.Size([3, 2])

Output:
tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],
        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],
        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],
       grad_fn=&lt;AddmmBackward0&gt;)

Output shape: torch.Size([3, 6])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>질문:</strong> 위에서 <code>in_features</code>를 2에서 3으로 변경하면 어떻게 되나요? 오류가 발생하나요? 오류에 대응하기 위해 입력(<code>x</code>)의 모양을 어떻게 변경할 수 있을까요? 힌트: 위에서 <code>tensor_B</code>에 무엇을 해야 했나요?</p>
</blockquote>
<p>행렬 곱셈을 처음 접한다면 처음에는 혼란스러운 주제일 수 있습니다.</p>
<p>하지만 몇 번 연습하고 신경망을 직접 분석해 보면 어디에나 있다는 것을 알게 될 것입니다.</p>
<p>기억하세요, 행렬 곱셈이 여러분에게 필요한 전부입니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_matrix_multiplication_is_all_you_need.jpeg" class="img-fluid figure-img"></p>
<figcaption>행렬 곱셈이 여러분에게 필요한 전부입니다</figcaption>
</figure>
</div>
<p><em>신경망 레이어를 파헤치고 직접 구축하기 시작하면 어디에서나 행렬 곱셈을 발견하게 될 것입니다. <strong>출처:</strong> https://marksaroufim.substack.com/p/working-class-deep-learner</em></p>
<section id="최소-최대-평균-합계-등-찾기-집계" class="level3">
<h3 class="anchored" data-anchor-id="최소-최대-평균-합계-등-찾기-집계">최소, 최대, 평균, 합계 등 찾기 (집계)</h3>
<p>텐서를 조작하는 몇 가지 방법을 살펴보았으니, 이제 텐서를 집계하는(많은 값에서 적은 값으로 가는) 몇 가지 방법을 살펴보겠습니다.</p>
<p>먼저 텐서를 생성한 다음 그 텐서의 최대값, 최소값, 평균 및 합계를 구합니다.</p>
<div id="cell-87" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="034013c1-b384-4a0d-edf8-295ed3a456f1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서 생성</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">100</span>, <span class="dv">10</span>)</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])</code></pre>
</div>
</div>
<p>이제 집계를 수행해 봅시다.</p>
<div id="cell-89" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3aa238c7-646f-434f-a55c-292aabef7227">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"최소값: </span><span class="sc">{</span>x<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"최대값: </span><span class="sc">{</span>x<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"평균: {x.mean()}") # 오류 발생</span></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"평균: </span><span class="sc">{</span>x<span class="sc">.</span><span class="bu">type</span>(torch.float32)<span class="sc">.</span>mean()<span class="sc">}</span><span class="ss">"</span>) <span class="co"># float 데이터 타입 없이는 작동하지 않음</span></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"합계: </span><span class="sc">{</span>x<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Minimum: 0
Maximum: 90
Mean: 45.0
Sum: 450</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>참고:</strong> <code>torch.mean()</code>과 같은 일부 메서드는 텐서가 <code>torch.float32</code>(가장 일반적임) 또는 다른 특정 데이터 타입이어야 하며, 그렇지 않으면 연산이 실패한다는 것을 알 수 있습니다.</p>
</blockquote>
<p><code>torch</code> 메서드를 사용하여 위와 동일하게 수행할 수도 있습니다.</p>
<div id="cell-91" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="9c86d805-eef2-465c-e2c8-2bccd515e6d5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">max</span>(x), torch.<span class="bu">min</span>(x), torch.mean(x.<span class="bu">type</span>(torch.float32)), torch.<span class="bu">sum</span>(x)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>(tensor(90), tensor(0), tensor(45.), tensor(450))</code></pre>
</div>
</div>
</section>
<section id="위치별-최소최대" class="level3">
<h3 class="anchored" data-anchor-id="위치별-최소최대">위치별 최소/최대</h3>
<p>각각 <a href="https://pytorch.org/docs/stable/generated/torch.argmax.html"><code>torch.argmax()</code></a> 및 <a href="https://pytorch.org/docs/stable/generated/torch.argmin.html"><code>torch.argmin()</code></a>을 사용하여 최대값 또는 최소값이 발생하는 텐서의 인덱스를 찾을 수도 있습니다.</p>
<p>이는 실제 값이 아닌 가장 높은(또는 가장 낮은) 값이 있는 위치만 원할 때 유용합니다(나중에 <a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html">softmax 활성화 함수</a>를 사용할 때 이 내용을 보게 될 것입니다).</p>
<div id="cell-93" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="01e0740e-c34f-469b-9c8f-9e6e5f0363af">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서 생성</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.arange(<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">10</span>)</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"텐서: </span><span class="sc">{</span>tensor<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 최대값 및 최소값의 인덱스 반환</span></span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"최대값이 있는 인덱스: </span><span class="sc">{</span>tensor<span class="sc">.</span>argmax()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"최소값이 있는 인덱스: </span><span class="sc">{</span>tensor<span class="sc">.</span>argmin()<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])
Index where max value occurs: 8
Index where min value occurs: 0</code></pre>
</div>
</div>
</section>
<section id="텐서-데이터-타입-변경" class="level3">
<h3 class="anchored" data-anchor-id="텐서-데이터-타입-변경">텐서 데이터 타입 변경</h3>
<p>앞서 언급했듯이 딥러닝 연산의 일반적인 문제는 텐서의 데이터 타입이 서로 다른 것입니다.</p>
<p>하나의 텐서가 <code>torch.float64</code>이고 다른 하나가 <code>torch.float32</code>이면 오류가 발생할 수 있습니다.</p>
<p>하지만 해결 방법이 있습니다.</p>
<p><a href="https://pytorch.org/docs/stable/generated/torch.Tensor.type.html"><code>torch.Tensor.type(dtype=None)</code></a>을 사용하여 텐서의 데이터 타입을 변경할 수 있습니다. 여기서 <code>dtype</code> 매개변수는 사용하려는 데이터 타입입니다.</p>
<p>먼저 텐서를 생성하고 데이터 타입을 확인해 보겠습니다(기본값은 <code>torch.float32</code>입니다).</p>
<div id="cell-95" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="507f1ade-7c7a-4172-fa48-60c9ac4831c0">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서 생성 및 데이터 타입 확인</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.arange(<span class="fl">10.</span>, <span class="fl">100.</span>, <span class="fl">10.</span>)</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>tensor.dtype</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>torch.float32</code></pre>
</div>
</div>
<p>이제 이전과 동일하게 다른 텐서를 생성하지만 데이터 타입을 <code>torch.float16</code>으로 변경해 보겠습니다.</p>
<div id="cell-97" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="96e5ce12-bc29-4a2b-f81c-bfc89ea2d075">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co"># float16 텐서 생성</span></span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>tensor_float16 <span class="op">=</span> tensor.<span class="bu">type</span>(torch.float16)</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>tensor_float16</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)</code></pre>
</div>
</div>
<p>그리고 <code>torch.int8</code> 텐서를 만들기 위해 비슷한 작업을 수행할 수 있습니다.</p>
<div id="cell-99" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="667da17f-e38f-404a-bd2d-63683e45c99a">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># int8 텐서 생성</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>tensor_int8 <span class="op">=</span> tensor.<span class="bu">type</span>(torch.int8)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>tensor_int8</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>참고:</strong> 서로 다른 데이터 타입은 처음에는 혼란스러울 수 있습니다. 하지만 이렇게 생각해 보세요. 숫자(예: 32, 16, 8)가 작을수록 컴퓨터가 값을 덜 정밀하게 저장합니다. 저장 용량이 적으면 일반적으로 계산 속도가 빨라지고 전체 모델 크기가 작아집니다. 모바일 기반 신경망은 종종 8비트 정수로 작동하는데, float32 버전보다 작고 실행 속도가 빠르지만 정확도는 떨어집니다. 이에 대한 자세한 내용은 <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">컴퓨팅 정밀도</a>에 대해 읽어보시기 바랍니다.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>과제:</strong> 지금까지 꽤 많은 텐서 메서드를 다루었지만 <a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code> 문서</a>에는 훨씬 더 많은 메서드가 있습니다. 10분 정도 시간을 내어 스크롤하면서 눈에 띄는 것을 찾아보시길 권장합니다. 클릭해 본 다음 직접 코드로 작성하여 어떤 일이 일어나는지 확인해 보세요.</p>
</blockquote>
</section>
<section id="재구조화-쌓기-압축-및-압축-해제-reshaping-stacking-squeezing-and-unsqueezing" class="level3">
<h3 class="anchored" data-anchor-id="재구조화-쌓기-압축-및-압축-해제-reshaping-stacking-squeezing-and-unsqueezing">재구조화, 쌓기, 압축 및 압축 해제 (Reshaping, stacking, squeezing and unsqueezing)</h3>
<p>종종 내부의 값을 실제로 변경하지 않고 텐서의 모양을 바꾸거나 차원을 변경하고 싶을 때가 있습니다.</p>
<p>이를 위해 인기 있는 메서드는 다음과 같습니다.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>메서드</th>
<th>한 줄 설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape"><code>torch.reshape(input, shape)</code></a></td>
<td><code>input</code>을 <code>shape</code>(호환되는 경우)로 재구조화함. <code>torch.Tensor.reshape()</code>도 사용 가능.</td>
</tr>
<tr class="even">
<td><a href="https://pytorch.org/docs/stable/generated/torch.Tensor.view.html"><code>torch.Tensor.view(shape)</code></a></td>
<td>원래 텐서의 다른 <code>shape</code> 뷰(view)를 반환하지만 원래 텐서와 동일한 데이터를 공유함.</td>
</tr>
<tr class="odd">
<td><a href="https://pytorch.org/docs/1.9.1/generated/torch.stack.html"><code>torch.stack(tensors, dim=0)</code></a></td>
<td>새로운 차원(<code>dim</code>)을 따라 일련의 <code>tensors</code>를 결합함. 모든 <code>tensors</code>는 크기가 같아야 함.</td>
</tr>
<tr class="even">
<td><a href="https://pytorch.org/docs/stable/generated/torch.squeeze.html"><code>torch.squeeze(input)</code></a></td>
<td><code>input</code>에서 값이 <code>1</code>인 모든 차원을 제거(압축)함.</td>
</tr>
<tr class="odd">
<td><a href="https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html"><code>torch.unsqueeze(input, dim)</code></a></td>
<td><code>dim</code> 위치에 값이 <code>1</code>인 차원이 추가된 <code>input</code>을 반환함.</td>
</tr>
<tr class="even">
<td><a href="https://pytorch.org/docs/stable/generated/torch.permute.html"><code>torch.permute(input, dims)</code></a></td>
<td>차원이 <code>dims</code>로 순열(재배열)된 원래 <code>input</code>의 <em>뷰</em>를 반환함.</td>
</tr>
</tbody>
</table>
<p>왜 이런 작업을 할까요?</p>
<p>딥러닝 모델(신경망)은 어떤 방식으로든 텐서를 조작하는 것이 전부이기 때문입니다. 그리고 행렬 곱셈의 규칙 때문에 모양이 맞지 않으면 오류가 발생합니다. 이러한 메서드는 텐서의 올바른 요소가 다른 텐서의 올바른 요소와 섞이도록 도와줍니다.</p>
<p>한번 시도해 봅시다.</p>
<p>먼저 텐서를 생성합니다.</p>
<div id="cell-102" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f7f2719c-15ce-406b-dc8f-4477046cd5d9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서 생성</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="fl">1.</span>, <span class="fl">8.</span>)</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>x, x.shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))</code></pre>
</div>
</div>
<p>이제 <code>torch.reshape()</code>를 사용하여 차원을 추가해 보겠습니다.</p>
<div id="cell-104" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="c519d59e-85f1-4a10-eaaa-acb487028e3a">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 추가 차원 더하기</span></span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>x_reshaped <span class="op">=</span> x.reshape(<span class="dv">1</span>, <span class="dv">7</span>)</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>x_reshaped, x_reshaped.shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))</code></pre>
</div>
</div>
<p><code>torch.view()</code>를 사용하여 뷰를 변경할 수도 있습니다.</p>
<div id="cell-106" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3df1b0d6-2548-4ecc-ca25-0c4e28a6e536">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 뷰 변경 (원본과 동일한 데이터를 유지하면서 뷰만 변경)</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 자세히 보기: https://stackoverflow.com/a/54507446/7900723</span></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> x.view(<span class="dv">1</span>, <span class="dv">7</span>)</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>z, z.shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))</code></pre>
</div>
</div>
<p><code>torch.view()</code>로 텐서의 뷰를 변경하는 것은 실제로는 <em>동일한</em> 텐서의 새로운 뷰를 생성할 뿐이라는 점을 기억하세요.</p>
<p>따라서 뷰를 변경하면 원본 텐서도 변경됩니다.</p>
<div id="cell-108" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="668d194d-dd0a-4db1-da00-9c3fd8849186">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># z를 변경하면 x도 변경됨</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>z[:, <span class="dv">0</span>] <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>z, x</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))</code></pre>
</div>
</div>
<p>새로운 텐서를 자신 위에 네 번 쌓고 싶다면 <code>torch.stack()</code>을 사용하여 수행할 수 있습니다.</p>
<div id="cell-110" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="703e8568-61df-4ebd-f4d3-a6366dc265c0">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서를 서로 위에 쌓기</span></span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>x_stacked <span class="op">=</span> torch.stack([x, x, x, x], dim<span class="op">=</span><span class="dv">0</span>) <span class="co"># dim을 dim=1로 변경하고 어떤 일이 일어나는지 확인해 보세요</span></span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>x_stacked</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>tensor([[5., 2., 3., 4., 5., 6., 7.],
        [5., 2., 3., 4., 5., 6., 7.],
        [5., 2., 3., 4., 5., 6., 7.],
        [5., 2., 3., 4., 5., 6., 7.]])</code></pre>
</div>
</div>
<p>텐서에서 모든 단일 차원을 제거하는 것은 어떨까요?</p>
<p>그렇게 하려면 <code>torch.squeeze()</code>를 사용할 수 있습니다(저는 이를 텐서를 <em>압축</em>하여 1보다 큰 차원만 남게 하는 것으로 기억합니다).</p>
<div id="cell-112" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="dd0645a6-1cdd-46bc-a3a2-433d9cd09336">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"이전 텐서: </span><span class="sc">{</span>x_reshaped<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"이전 모양: </span><span class="sc">{</span>x_reshaped<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a><span class="co"># x_reshaped에서 추가 차원 제거</span></span>
<span id="cb110-5"><a href="#cb110-5" aria-hidden="true" tabindex="-1"></a>x_squeezed <span class="op">=</span> x_reshaped.squeeze()</span>
<span id="cb110-6"><a href="#cb110-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">새로운 텐서: </span><span class="sc">{</span>x_squeezed<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb110-7"><a href="#cb110-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"새로운 모양: </span><span class="sc">{</span>x_squeezed<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])
Previous shape: torch.Size([1, 7])

New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])
New shape: torch.Size([7])</code></pre>
</div>
</div>
<p>그리고 <code>torch.squeeze()</code>의 반대 작업을 하려면 <code>torch.unsqueeze()</code>를 사용하여 특정 인덱스에 값이 1인 차원을 추가할 수 있습니다.</p>
<div id="cell-114" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="da60e019-3ea6-42f8-8e47-ba037ead737f">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"이전 텐서: </span><span class="sc">{</span>x_squeezed<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"이전 모양: </span><span class="sc">{</span>x_squeezed<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a><span class="co">## unsqueeze로 추가 차원 더하기</span></span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a>x_unsqueezed <span class="op">=</span> x_squeezed.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">새로운 텐서: </span><span class="sc">{</span>x_unsqueezed<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb112-7"><a href="#cb112-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"새로운 모양: </span><span class="sc">{</span>x_unsqueezed<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])
Previous shape: torch.Size([7])

New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])
New shape: torch.Size([1, 7])</code></pre>
</div>
</div>
<p><code>torch.permute(input, dims)</code>를 사용하여 축 값의 순서를 재배열할 수도 있습니다. 여기서 <code>input</code>은 새로운 <code>dims</code>를 가진 <em>뷰</em>로 변환됩니다.</p>
<div id="cell-116" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="6853328b-a1cf-4470-f366-106a231a189c">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 특정 모양의 텐서 생성</span></span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>x_original <span class="op">=</span> torch.rand(size<span class="op">=</span>(<span class="dv">224</span>, <span class="dv">224</span>, <span class="dv">3</span>))</span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 원본 텐서를 순열하여 축 순서 재배열</span></span>
<span id="cb114-5"><a href="#cb114-5" aria-hidden="true" tabindex="-1"></a>x_permuted <span class="op">=</span> x_original.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>) <span class="co"># 축을 0-&gt;1, 1-&gt;2, 2-&gt;0으로 이동</span></span>
<span id="cb114-6"><a href="#cb114-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-7"><a href="#cb114-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"이전 모양: </span><span class="sc">{</span>x_original<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb114-8"><a href="#cb114-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"새로운 모양: </span><span class="sc">{</span>x_permuted<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Previous shape: torch.Size([224, 224, 3])
New shape: torch.Size([3, 224, 224])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>참고</strong>: 순열(permuting)은 <em>뷰</em>(원본과 동일한 데이터를 공유함)를 반환하므로 순열된 텐서의 값은 원본 텐서와 동일하며 뷰에서 값을 변경하면 원본의 값도 변경됩니다.</p>
</blockquote>
</section>
</section>
<section id="인덱싱-텐서에서-데이터-선택" class="level2">
<h2 class="anchored" data-anchor-id="인덱싱-텐서에서-데이터-선택">인덱싱 (텐서에서 데이터 선택)</h2>
<p>때로는 텐서에서 특정 데이터(예: 첫 번째 열 또는 두 번째 행만)를 선택하고 싶을 때가 있습니다.</p>
<p>그렇게 하려면 인덱싱을 사용할 수 있습니다.</p>
<p>파이썬 리스트나 NumPy 배열에서 인덱싱을 해보셨다면 PyTorch 텐서의 인덱싱도 매우 유사합니다.</p>
<div id="cell-119" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="05a72c08-5f8c-433a-cd31-46065686f825">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서 생성</span></span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">1</span>, <span class="dv">10</span>).reshape(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>x, x.shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>(tensor([[[1, 2, 3],
          [4, 5, 6],
          [7, 8, 9]]]), torch.Size([1, 3, 3]))</code></pre>
</div>
</div>
<p>값 인덱싱은 바깥쪽 차원에서 안쪽 차원 순서로 진행됩니다(대괄호를 확인하세요).</p>
<div id="cell-121" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="cf6c0936-7600-4af4-9b6f-f6b8ac9b4c05">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 대괄호별로 인덱싱해 봅시다</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"첫 번째 대괄호:</span><span class="ch">\n</span><span class="sc">{</span>x[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"두 번째 대괄호: </span><span class="sc">{</span>x[<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"세 번째 대괄호: </span><span class="sc">{</span>x[<span class="dv">0</span>][<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>First square bracket:
tensor([[1, 2, 3],
        [4, 5, 6],
        [7, 8, 9]])
Second square bracket: tensor([1, 2, 3])
Third square bracket: 1</code></pre>
</div>
</div>
<p><code>:</code>을 사용하여 “이 차원의 모든 값”을 지정한 다음 쉼표(<code>,</code>)를 사용하여 다른 차원을 추가할 수도 있습니다.</p>
<div id="cell-123" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="a91f9b73-f8f0-476a-9c69-fcd03b042f6b">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 0번째 차원의 모든 값과 1번째 차원의 0번 인덱스 가져오기</span></span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>x[:, <span class="dv">0</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>tensor([[1, 2, 3]])</code></pre>
</div>
</div>
<div id="cell-124" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="8165cfd9-a88d-4212-8c45-1eb84ef5be83">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 0번째 및 1번째 차원의 모든 값을 가져오되 2번째 차원의 인덱스 1만 가져오기</span></span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>x[:, :, <span class="dv">1</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>tensor([[2, 5, 8]])</code></pre>
</div>
</div>
<div id="cell-125" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="12fa4749-cf52-4e88-c2c0-44d26aeb633c">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 0차원의 모든 값을 가져오되 1차원과 2차원의 인덱스 1 값만 가져오기</span></span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>x[:, <span class="dv">1</span>, <span class="dv">1</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>tensor([5])</code></pre>
</div>
</div>
<div id="cell-126" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="69eadeb9-11b3-4b48-cb95-0b3305c1274c">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 0번째 및 1번째 차원의 인덱스 0과 2번째 차원의 모든 값 가져오기</span></span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>x[<span class="dv">0</span>, <span class="dv">0</span>, :] <span class="co"># x[0][0]과 동일</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>tensor([1, 2, 3])</code></pre>
</div>
</div>
<p>인덱싱은 처음에는 상당히 혼란스러울 수 있으며, 특히 텐서가 커질수록 더 그렇습니다(저도 올바르게 인덱싱하기 위해 여러 번 시도하곤 합니다). 하지만 약간의 연습과 데이터 탐험가의 좌우명인 (<strong><em>시각화, 시각화, 시각화</em></strong>)를 따르다 보면 요령을 터득하기 시작할 것입니다.</p>
</section>
<section id="pytorch-텐서와-numpy" class="level2">
<h2 class="anchored" data-anchor-id="pytorch-텐서와-numpy">PyTorch 텐서와 NumPy</h2>
<p>NumPy는 인기 있는 파이썬 수치 컴퓨팅 라이브러리이므로 PyTorch는 이와 잘 상호 작용할 수 있는 기능을 갖추고 있습니다.</p>
<p>NumPy에서 PyTorch로(그리고 그 반대로) 전환하는 데 사용하려는 두 가지 주요 메서드는 다음과 같습니다. * <a href="https://pytorch.org/docs/stable/generated/torch.from_numpy.html"><code>torch.from_numpy(ndarray)</code></a> - NumPy 배열 -&gt; PyTorch 텐서. * <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html"><code>torch.Tensor.numpy()</code></a> - PyTorch 텐서 -&gt; NumPy 배열.</p>
<p>한번 시도해 봅시다.</p>
<div id="cell-129" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="86155a63-01f9-4372-e889-61a65ebf0fb1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="co"># NumPy 배열에서 텐서로</span></span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb128-4"><a href="#cb128-4" aria-hidden="true" tabindex="-1"></a>array <span class="op">=</span> np.arange(<span class="fl">1.0</span>, <span class="fl">8.0</span>)</span>
<span id="cb128-5"><a href="#cb128-5" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.from_numpy(array)</span>
<span id="cb128-6"><a href="#cb128-6" aria-hidden="true" tabindex="-1"></a>array, tensor</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>(array([1., 2., 3., 4., 5., 6., 7.]),
 tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>참고:</strong> 기본적으로 NumPy 배열은 <code>float64</code> 데이터 타입으로 생성되며 이를 PyTorch 텐서로 변환하면 동일한 데이터 타입이 유지됩니다(위와 같이).</p>
<p>그러나 많은 PyTorch 계산은 기본적으로 <code>float32</code>를 사용합니다.</p>
<p>따라서 NumPy 배열(float64) -&gt; PyTorch 텐서(float64) -&gt; PyTorch 텐서(float32)로 변환하려면 <code>tensor = torch.from_numpy(array).type(torch.float32)</code>를 사용할 수 있습니다.</p>
</blockquote>
<p>위에서 <code>tensor</code>를 재할당했으므로 텐서를 변경해도 배열은 그대로 유지됩니다.</p>
<div id="cell-131" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="efd21eb9-0010-436a-dc29-f851e3d7d77a">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 배열을 변경하고 텐서는 유지하기</span></span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>array <span class="op">=</span> array <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a>array, tensor</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>(array([2., 3., 4., 5., 6., 7., 8.]),
 tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))</code></pre>
</div>
</div>
<p>PyTorch 텐서에서 NumPy 배열로 가려면 <code>tensor.numpy()</code>를 호출하면 됩니다.</p>
<div id="cell-133" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="54d6f347-d3f6-44df-9155-83d980c31780">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서에서 NumPy 배열로</span></span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.ones(<span class="dv">7</span>) <span class="co"># dtype=float32인 1로 구성된 텐서 생성</span></span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a>numpy_tensor <span class="op">=</span> tensor.numpy() <span class="co"># 변경하지 않는 한 dtype=float32가 됨</span></span>
<span id="cb132-4"><a href="#cb132-4" aria-hidden="true" tabindex="-1"></a>tensor, numpy_tensor</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>(tensor([1., 1., 1., 1., 1., 1., 1.]),
 array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))</code></pre>
</div>
</div>
<p>그리고 위와 동일한 규칙이 적용됩니다. 원래 <code>tensor</code>를 변경해도 새로운 <code>numpy_tensor</code>는 그대로 유지됩니다.</p>
<div id="cell-135" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="100678a4-c220-4a44-e4a5-0542359cb9de">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서를 변경하고 배열은 동일하게 유지하기</span></span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> tensor <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>tensor, numpy_tensor</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>(tensor([2., 2., 2., 2., 2., 2., 2.]),
 array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))</code></pre>
</div>
</div>
</section>
<section id="재현성-무작위성-제어하기" class="level2">
<h2 class="anchored" data-anchor-id="재현성-무작위성-제어하기">재현성 (무작위성 제어하기)</h2>
<p>신경망과 머신러닝에 대해 더 배우다 보면 무작위성이 얼마나 큰 역할을 하는지 알게 될 것입니다.</p>
<p>음, 실제로는 의사 무작위성(pseudorandomness)입니다. 결국 설계된 대로 컴퓨터는 근본적으로 결정론적(각 단계가 예측 가능함)이므로 컴퓨터가 생성하는 무작위성은 시뮬레이션된 무작위성입니다(이에 대해서도 논란이 있지만 저는 컴퓨터 과학자가 아니므로 직접 더 알아보시기 바랍니다).</p>
<p>그렇다면 이것이 신경망 및 딥러닝과 어떤 관련이 있을까요?</p>
<p>우리는 신경망이 데이터의 패턴을 설명하기 위해 무작위 숫자로 시작하고(이 숫자는 서투른 설명입니다), 텐서 연산(및 아직 논의하지 않은 몇 가지 다른 것들)을 사용하여 해당 무작위 숫자를 개선하여 데이터의 패턴을 더 잘 설명하려고 시도한다는 것을 논의했습니다.</p>
<p>요약하자면:</p>
<p><code>무작위 숫자로 시작 -&gt; 텐서 연산 -&gt; 더 나아지도록 시도 (반복 반복 반복)</code></p>
<p>무작위성은 훌륭하고 강력하지만 때로는 무작위성이 조금 덜했으면 할 때가 있습니다.</p>
<p>왜일까요?</p>
<p>반복 가능한 실험을 수행할 수 있기 때문입니다.</p>
<p>예를 들어, 여러분이 성능 X를 달성할 수 있는 알고리즘을 만들었다고 가정해 봅시다.</p>
<p>그러면 친구가 여러분이 미치지 않았는지 확인하기 위해 시도해 봅니다.</p>
<p>그들은 어떻게 그런 일을 할 수 있을까요?</p>
<p>여기서 <strong>재현성(reproducibility)</strong>이 등장합니다.</p>
<p>다시 말해, 여러분이 얻은 것과 동일한 코드를 실행하여 여러분의 컴퓨터에서와 동일한(또는 매우 유사한) 결과를 내 컴퓨터에서도 얻을 수 있습니까?</p>
<p>PyTorch에서 재현성의 간단한 예를 들어봅시다.</p>
<p>먼저 두 개의 무작위 텐서를 생성해 보겠습니다. 무작위이기 때문에 서로 다를 것으로 예상하시죠?</p>
<div id="cell-137" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="73b34154-734f-496f-9b55-b6aaa137e854">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 두 개의 무작위 텐서 생성</span></span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>random_tensor_A <span class="op">=</span> torch.rand(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>random_tensor_B <span class="op">=</span> torch.rand(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb136-6"><a href="#cb136-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-7"><a href="#cb136-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"텐서 A:</span><span class="ch">\n</span><span class="sc">{</span>random_tensor_A<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb136-8"><a href="#cb136-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"텐서 B:</span><span class="ch">\n</span><span class="sc">{</span>random_tensor_B<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb136-9"><a href="#cb136-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"텐서 A와 텐서 B가 같습니까? (어디든)"</span>)</span>
<span id="cb136-10"><a href="#cb136-10" aria-hidden="true" tabindex="-1"></a>random_tensor_A <span class="op">==</span> random_tensor_B</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tensor A:
tensor([[0.8016, 0.3649, 0.6286, 0.9663],
        [0.7687, 0.4566, 0.5745, 0.9200],
        [0.3230, 0.8613, 0.0919, 0.3102]])

Tensor B:
tensor([[0.9536, 0.6002, 0.0351, 0.6826],
        [0.3743, 0.5220, 0.1336, 0.9666],
        [0.9754, 0.8474, 0.8988, 0.1105]])

Does Tensor A equal Tensor B? (anywhere)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>tensor([[False, False, False, False],
        [False, False, False, False],
        [False, False, False, False]])</code></pre>
</div>
</div>
<p>예상했던 대로 텐서는 서로 다른 값으로 나옵니다.</p>
<p>하지만 <em>동일한</em> 값을 가진 두 개의 무작위 텐서를 만들고 싶다면 어떻게 해야 할까요?</p>
<p>즉, 텐서에 여전히 무작위 값이 포함되어 있지만 동일한 풍미(flavour)를 갖기를 원하는 것입니다.</p>
<p>여기서 <a href="https://pytorch.org/docs/stable/generated/torch.manual_seed.html"><code>torch.manual_seed(seed)</code></a>가 등장합니다. 여기서 <code>seed</code>는 무작위성에 풍미를 더하는 정수(<code>42</code>와 같지만 무엇이든 될 수 있음)입니다.</p>
<p>좀 더 <em>풍미가 더해진</em> 무작위 텐서를 만들어 시도해 봅시다.</p>
<div id="cell-139" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="4d11d38e-4406-4aff-9a81-cf13aa89ee5f">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 무작위 시드 설정</span></span>
<span id="cb139-5"><a href="#cb139-5" aria-hidden="true" tabindex="-1"></a>RANDOM_SEED<span class="op">=</span><span class="dv">42</span> <span class="co"># 이 값을 다른 값으로 변경하고 아래 숫자에 어떤 일이 일어나는지 확인해 보세요</span></span>
<span id="cb139-6"><a href="#cb139-6" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed<span class="op">=</span>RANDOM_SEED) </span>
<span id="cb139-7"><a href="#cb139-7" aria-hidden="true" tabindex="-1"></a>random_tensor_C <span class="op">=</span> torch.rand(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb139-8"><a href="#cb139-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-9"><a href="#cb139-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 새로운 rand()가 호출될 때마다 시드를 재설정해야 함</span></span>
<span id="cb139-10"><a href="#cb139-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 이것이 없으면 tensor_D는 tensor_C와 달라짐</span></span>
<span id="cb139-11"><a href="#cb139-11" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(seed<span class="op">=</span>RANDOM_SEED) <span class="co"># 이 라인을 주석 처리하고 어떤 일이 일어나는지 확인해 보세요</span></span>
<span id="cb139-12"><a href="#cb139-12" aria-hidden="true" tabindex="-1"></a>random_tensor_D <span class="op">=</span> torch.rand(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb139-13"><a href="#cb139-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-14"><a href="#cb139-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"텐서 C:</span><span class="ch">\n</span><span class="sc">{</span>random_tensor_C<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb139-15"><a href="#cb139-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"텐서 D:</span><span class="ch">\n</span><span class="sc">{</span>random_tensor_D<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb139-16"><a href="#cb139-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"텐서 C와 텐서 D가 같습니까? (어디든)"</span>)</span>
<span id="cb139-17"><a href="#cb139-17" aria-hidden="true" tabindex="-1"></a>random_tensor_C <span class="op">==</span> random_tensor_D</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tensor C:
tensor([[0.8823, 0.9150, 0.3829, 0.9593],
        [0.3904, 0.6009, 0.2566, 0.7936],
        [0.9408, 0.1332, 0.9346, 0.5936]])

Tensor D:
tensor([[0.8823, 0.9150, 0.3829, 0.9593],
        [0.3904, 0.6009, 0.2566, 0.7936],
        [0.9408, 0.1332, 0.9346, 0.5936]])

Does Tensor C equal Tensor D? (anywhere)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>tensor([[True, True, True, True],
        [True, True, True, True],
        [True, True, True, True]])</code></pre>
</div>
</div>
<p>좋네요!</p>
<p>시드 설정이 작동한 것 같습니다.</p>
<blockquote class="blockquote">
<p><strong>리소스:</strong> 우리가 방금 다룬 내용은 PyTorch 재현성의 겉핥기 수준일 뿐입니다. 일반적인 재현성과 무작위 시드에 대한 자세한 내용은 다음을 확인하세요. * <a href="https://pytorch.org/docs/stable/notes/randomness.html">PyTorch 재현성 문서</a> (10분 동안 이 문서를 읽어보는 것이 좋은 연습이 될 것입니다. 지금 당장 이해하지 못하더라도 이를 인지하고 있는 것이 중요합니다). * <a href="https://en.wikipedia.org/wiki/Random_seed">Wikipedia 무작위 시드 페이지</a> (무작위 시드 및 의사 무작위성에 대한 좋은 개요를 제공합니다).</p>
</blockquote>
</section>
<section id="gpu에서-텐서-실행하기-및-계산-가속화" class="level2">
<h2 class="anchored" data-anchor-id="gpu에서-텐서-실행하기-및-계산-가속화">GPU에서 텐서 실행하기 (및 계산 가속화)</h2>
<p>딥러닝 알고리즘은 많은 수치 연산을 필요로 합니다.</p>
<p>그리고 기본적으로 이러한 연산은 종종 CPU(중앙 처리 장치)에서 수행됩니다.</p>
<p>하지만 GPU(그래픽 처리 장치)라는 또 다른 일반적인 하드웨어가 있는데, 이는 신경망이 필요로 하는 특정 유형의 연산(행렬 곱셈)을 수행하는 데 종종 CPU보다 훨씬 빠릅니다.</p>
<p>여러분의 컴퓨터에도 하나 있을 수 있습니다.</p>
<p>그렇다면 신경망을 학습시킬 때마다 가급적 이를 사용해야 합니다. 왜냐하면 학습 시간을 비약적으로 단축할 수 있기 때문입니다.</p>
<p>먼저 GPU에 액세스하고 다음으로 PyTorch가 GPU를 사용하도록 하는 몇 가지 방법이 있습니다.</p>
<blockquote class="blockquote">
<p><strong>참고:</strong> 이 과정 전반에서 “GPU”를 언급할 때는 달리 명시되지 않는 한 <a href="https://developer.nvidia.com/cuda-gpus">CUDA가 활성화된 Nvidia GPU</a>를 의미합니다(CUDA는 GPU를 그래픽뿐만 아니라 일반적인 용도의 컴퓨팅에 사용할 수 있도록 도와주는 컴퓨팅 플랫폼 및 API입니다).</p>
</blockquote>
<section id="gpu-확보하기" class="level3">
<h3 class="anchored" data-anchor-id="gpu-확보하기">1. GPU 확보하기</h3>
<p>GPU라고 말할 때 무슨 일이 일어나고 있는지 이미 알고 계실 수도 있습니다. 하지만 그렇지 않다면 GPU에 액세스하는 몇 가지 방법이 있습니다.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><strong>방법</strong></th>
<th><strong>설정 난이도</strong></th>
<th><strong>장점</strong></th>
<th><strong>단점</strong></th>
<th><strong>설정 방법</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Google Colab</td>
<td>쉬움</td>
<td>무료 사용 가능, 설정 거의 불필요, 링크만으로 작업 공유 가능</td>
<td>데이터 출력 저장 안 됨, 컴퓨팅 제한적, 타임아웃 발생 가능</td>
<td><a href="https://colab.research.google.com/notebooks/gpu.ipynb">Google Colab 가이드 따르기</a></td>
</tr>
<tr class="even">
<td>개인 기기 사용</td>
<td>중간</td>
<td>자신의 기기에서 모든 것을 로컬로 실행</td>
<td>GPU는 무료가 아님, 초기 비용 필요</td>
<td><a href="https://pytorch.org/get-started/locally/">PyTorch 설치 지침</a> 따르기</td>
</tr>
<tr class="odd">
<td>클라우드 컴퓨팅 (AWS, GCP, Azure)</td>
<td>중간-어려움</td>
<td>적은 초기 비용, 거의 무한한 컴퓨팅 액세스</td>
<td>계속 실행하면 비쌀 수 있음, 올바르게 설정하는 데 시간이 걸림</td>
<td><a href="https://pytorch.org/get-started/cloud-partners/">PyTorch 클라우드 설치 지침</a> 따르기</td>
</tr>
</tbody>
</table>
<p>GPU를 사용하기 위한 더 많은 옵션이 있지만 지금은 위의 세 가지면 충분합니다.</p>
<p>개인적으로 저는 소규모 실험(및 이 과정 제작)에는 Google Colab과 개인 컴퓨터를 혼용해서 사용하고, 더 많은 컴퓨팅 파워가 필요할 때는 클라우드 리소스를 활용합니다.</p>
<blockquote class="blockquote">
<p><strong>리소스:</strong> 직접 GPU를 구매하고 싶지만 무엇을 사야 할지 모르겠다면 <a href="https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/">Tim Dettmers의 훌륭한 가이드</a>를 참조하세요.</p>
</blockquote>
<p>Nvidia GPU에 액세스할 수 있는지 확인하려면 <code>!nvidia-smi</code>를 실행할 수 있습니다. 여기서 <code>!</code>(뱅이라고도 함)는 “이를 명령줄에서 실행하라”는 의미입니다.</p>
<div id="cell-143" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="77405db7-3494-4add-cfc7-8415e52a0412">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>nvidia<span class="op">-</span>smi</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Thu Feb 10 02:09:18 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |
| N/A   36C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+</code></pre>
</div>
</div>
<p>접근 가능한 Nvidia GPU가 없는 경우 위 명령은 다음과 같은 내용을 출력합니다.</p>
<pre><code>NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.</code></pre>
<p>이 경우 위로 돌아가 설치 단계를 따르세요.</p>
<p>GPU가 있는 경우 위 라인은 다음과 같은 내용을 출력합니다.</p>
<pre><code>Wed Jan 19 22:09:08 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |
| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+</code></pre>
</section>
<section id="pytorch가-gpu에서-실행되도록-하기" class="level3">
<h3 class="anchored" data-anchor-id="pytorch가-gpu에서-실행되도록-하기">2. PyTorch가 GPU에서 실행되도록 하기</h3>
<p>액세스할 준비가 된 GPU가 있으면 다음 단계는 PyTorch가 데이터를 저장(텐서)하고 데이터를 계산(텐서에 대한 연산 수행)하는 데 GPU를 사용하도록 하는 것입니다.</p>
<p>그렇게 하려면 <a href="https://pytorch.org/docs/stable/cuda.html"><code>torch.cuda</code></a> 패키지를 사용할 수 있습니다.</p>
<p>말로 설명하기보다 직접 해봅시다.</p>
<p><a href="https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available"><code>torch.cuda.is_available()</code></a>을 사용하여 PyTorch가 GPU에 액세스할 수 있는지 테스트할 수 있습니다.</p>
<div id="cell-146" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3a278a24-3ec3-4b1f-8f96-298086fa6ea6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="co"># GPU 확인</span></span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a>torch.cuda.is_available()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>True</code></pre>
</div>
</div>
<p>위 출력이 <code>True</code>이면 PyTorch가 GPU를 보고 사용할 수 있다는 뜻이고, <code>False</code>이면 GPU를 볼 수 없다는 뜻이므로 이 경우 설치 단계를 다시 거쳐야 합니다.</p>
<p>이제 CPU에서 실행되거나 GPU를 사용할 수 있는 경우 GPU에서 실행되도록 코드를 설정하고 싶다고 가정해 보겠습니다.</p>
<p>그렇게 하면 여러분이나 누군가가 코드를 실행하기로 결정하더라도 사용 중인 컴퓨팅 장치에 관계없이 코드가 작동할 것입니다.</p>
<p>사용 가능한 장치 종류를 저장하기 위해 <code>device</code> 변수를 생성해 보겠습니다.</p>
<div id="cell-148" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:35}}" data-outputid="8cca1643-645c-4b67-f1f5-37066f6b9549">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 장치 타입 설정</span></span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>device</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>'cuda'</code></pre>
</div>
</div>
<p>위 출력이 <code>"cuda"</code>이면 사용 가능한 CUDA 장치(GPU)를 사용하도록 모든 PyTorch 코드를 설정할 수 있고, <code>"cpu"</code>이면 PyTorch 코드가 CPU를 그대로 사용하게 됩니다.</p>
<blockquote class="blockquote">
<p><strong>참고:</strong> PyTorch에서는 <a href="https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code"><strong>장치에 구애받지 않는 코드(device agnostic code)</strong></a>를 작성하는 것이 가장 좋은 관행입니다. 이는 CPU(항상 사용 가능) 또는 GPU(사용 가능한 경우)에서 실행될 코드를 의미합니다.</p>
</blockquote>
<p>더 빠른 계산을 원하면 GPU를 사용할 수 있지만, <em>훨씬 더</em> 빠른 계산을 원하면 여러 개의 GPU를 사용할 수 있습니다.</p>
<p><a href="https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count"><code>torch.cuda.device_count()</code></a>를 사용하여 PyTorch가 액세스할 수 있는 GPU 수를 셀 수 있습니다.</p>
<div id="cell-150" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="de717df5-bb67-4900-805e-a6f00ad0b409">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 장치 수 세기</span></span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>torch.cuda.device_count()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>1</code></pre>
</div>
</div>
<p>PyTorch가 액세스할 수 있는 GPU 수를 아는 것은 하나의 GPU에서 특정 프로세스를 실행하고 다른 GPU에서 다른 프로세스를 실행하려는 경우에 유용합니다(PyTorch에는 <em>모든</em> GPU에서 프로세스를 실행할 수 있게 해주는 기능도 있습니다).</p>
</section>
<section id="gpu에-텐서및-모델-넣기" class="level3">
<h3 class="anchored" data-anchor-id="gpu에-텐서및-모델-넣기">3. GPU에 텐서(및 모델) 넣기</h3>
<p>텐서(및 모델, 나중에 보게 될 것입니다)를 특정 장치에서 실행하려면 해당 텐서(또는 모델)에 대해 <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.to.html"><code>to(device)</code></a>를 호출하면 됩니다. 여기서 <code>device</code>는 텐서(또는 모델)가 이동하려는 대상 장치입니다.</p>
<p>왜 이렇게 할까요?</p>
<p>GPU는 CPU보다 훨씬 빠른 수치 계산을 제공하며, GPU를 사용할 수 없는 경우 <strong>장치에 구애받지 않는 코드</strong>(위 참조) 덕분에 CPU에서 실행될 것이기 때문입니다.</p>
<blockquote class="blockquote">
<p><strong>참고:</strong> <code>to(device)</code>(예: <code>some_tensor.to(device)</code>)를 사용하여 텐서를 GPU에 넣으면 해당 텐서의 복사본이 반환됩니다. 즉, 동일한 텐서가 CPU와 GPU에 모두 있게 됩니다. 텐서를 덮어쓰려면 다음과 같이 재할당하세요.</p>
<p><code>some_tensor = some_tensor.to(device)</code></p>
</blockquote>
<p>텐서를 생성하고 GPU(사용 가능한 경우)에 넣어봅시다.</p>
<div id="cell-153" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2f4f6435-fdc4-4e99-e87c-9421c2100f36">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서 생성 (기본적으로 CPU에 있음)</span></span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb152-3"><a href="#cb152-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb152-4"><a href="#cb152-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서가 GPU에 있지 않음</span></span>
<span id="cb152-5"><a href="#cb152-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor, tensor.device)</span>
<span id="cb152-6"><a href="#cb152-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb152-7"><a href="#cb152-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서를 GPU로 이동 (사용 가능한 경우)</span></span>
<span id="cb152-8"><a href="#cb152-8" aria-hidden="true" tabindex="-1"></a>tensor_on_gpu <span class="op">=</span> tensor.to(device)</span>
<span id="cb152-9"><a href="#cb152-9" aria-hidden="true" tabindex="-1"></a>tensor_on_gpu</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([1, 2, 3]) cpu</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>tensor([1, 2, 3], device='cuda:0')</code></pre>
</div>
</div>
<p>GPU를 사용할 수 있는 경우 위 코드는 다음과 같은 내용을 출력합니다.</p>
<pre><code>tensor([1, 2, 3]) cpu
tensor([1, 2, 3], device='cuda:0')</code></pre>
<p>두 번째 텐서에 <code>device='cuda:0'</code>이 있는 것을 확인하세요. 이는 사용 가능한 0번째 GPU에 저장되었음을 의미합니다(GPU는 0부터 인덱싱되며, 두 개의 GPU를 사용할 수 있는 경우 각각 <code>'cuda:0'</code> 및 <code>'cuda:1'</code>부터 <code>'cuda:n'</code>까지입니다).</p>
</section>
<section id="텐서를-다시-cpu로-이동하기" class="level3">
<h3 class="anchored" data-anchor-id="텐서를-다시-cpu로-이동하기">4. 텐서를 다시 CPU로 이동하기</h3>
<p>텐서를 다시 CPU로 이동하고 싶다면 어떻게 해야 할까요?</p>
<p>예를 들어, NumPy와 텐서를 상호 작용시키고 싶을 때 이 작업이 필요합니다(NumPy는 GPU를 활용하지 않기 때문입니다).</p>
<p><code>tensor_on_gpu</code>에 대해 <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html"><code>torch.Tensor.numpy()</code></a> 메서드를 사용해 봅시다.</p>
<div id="cell-156" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:186}}" data-outputid="32e92f62-db28-4dc7-ce93-c2ab33229252">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 텐서가 GPU에 있으면 NumPy로 변환할 수 없음 (오류 발생)</span></span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>tensor_on_gpu.numpy()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">TypeError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-75-53175578f49e&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span class="ansi-red-fg"># 텐서가 GPU에 있으면 NumPy로 변환할 수 없음 (오류 발생)</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>tensor_on_gpu<span class="ansi-blue-fg">.</span>numpy<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">TypeError</span>: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.</pre>
</div>
</div>
</div>
<p>대신 텐서를 다시 CPU로 가져와 NumPy와 함께 사용하려면 <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html"><code>Tensor.cpu()</code></a>를 사용할 수 있습니다.</p>
<p>이는 텐서를 CPU 메모리로 복사하여 CPU에서 사용할 수 있도록 합니다.</p>
<div id="cell-158" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="9fffb6f2-c200-4f9c-d987-d9ab5d9cba49">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 대신 텐서를 다시 cpu로 복사</span></span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>tensor_back_on_cpu <span class="op">=</span> tensor_on_gpu.cpu().numpy()</span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>tensor_back_on_cpu</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>array([1, 2, 3])</code></pre>
</div>
</div>
<p>위 명령은 GPU 텐서의 복사본을 CPU 메모리로 반환하므로 원본 텐서는 여전히 GPU에 있습니다.</p>
<div id="cell-160" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="4cb931e2-7c8d-49b9-a7de-db3d3c6589b5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>tensor_on_gpu</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>tensor([1, 2, 3], device='cuda:0')</code></pre>
</div>
</div>
</section>
</section>
<section id="연습-문제" class="level2">
<h2 class="anchored" data-anchor-id="연습-문제">연습 문제</h2>
<ol type="1">
<li>문서 읽기 - 딥러닝(및 일반적인 코딩 학습)의 큰 부분은 사용 중인 특정 프레임워크의 문서에 익숙해지는 것입니다. 이 과정의 나머지 부분에서 PyTorch 문서를 많이 사용하게 될 것입니다. 따라서 다음 내용을 10분 동안 읽어보시기 바랍니다(지금 당장 이해가 되지 않더라도 괜찮습니다. 핵심은 완전한 이해가 아니라 인지하는 것입니다).</li>
</ol>
<ul>
<li><a href="https://pytorch.org/docs/stable/tensors.html#torch-tensor"><code>torch.Tensor</code></a>에 대한 문서.</li>
<li><a href="https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics"><code>torch.cuda</code></a>에 대한 문서.</li>
</ul>
<ol start="2" type="1">
<li>모양이 <code>(7, 7)</code>인 무작위 텐서를 만드세요.</li>
<li>2번의 텐서에 모양이 <code>(1, 7)</code>인 다른 무작위 텐서와 행렬 곱셈을 수행하세요(힌트: 두 번째 텐서를 전치해야 할 수도 있습니다).</li>
<li>무작위 시드를 <code>0</code>으로 설정하고 2번과 3번을 다시 수행하세요. 출력은 다음과 같아야 합니다.</li>
</ol>
<pre><code>(tensor([[1.8542],
         [1.9611],
         [2.2884],
         [3.0481],
         [1.7067],
         [2.5290],
         [1.7989]]), torch.Size([7, 1]))</code></pre>
<ol start="5" type="1">
<li>무작위 시드와 관련하여 <code>torch.manual_seed()</code>로 설정하는 방법을 보았는데 GPU에서도 동일한 방법이 있나요? (힌트: 이를 위해 <code>torch.cuda</code> 문서를 찾아봐야 합니다)</li>
</ol>
<ul>
<li>방법이 있다면 GPU 무작위 시드를 <code>1234</code>로 설정하세요.</li>
</ul>
<ol start="6" type="1">
<li>모양이 <code>(2, 3)</code>인 두 개의 무작위 텐서를 만들고 둘 다 GPU로 보내세요(이를 위해 GPU에 액세스해야 합니다). 텐서를 생성할 때 <code>torch.manual_seed(1234)</code>를 설정하세요(이것이 GPU 무작위 시드일 필요는 없습니다). 출력은 다음과 같아야 합니다.</li>
</ol>
<pre><code>Device: cuda
(tensor([[0.0290, 0.4019, 0.2598],
         [0.3666, 0.0583, 0.7006]], device='cuda:0'),
 tensor([[0.0518, 0.4681, 0.6738],
         [0.3315, 0.7837, 0.5631]], device='cuda:0'))</code></pre>
<ol start="7" type="1">
<li>6번에서 만든 텐서에 대해 행렬 곱셈을 수행하세요(여기서도 텐서 중 하나의 모양을 조정해야 할 수도 있습니다).</li>
<li>7번 출력의 최대값과 최소값을 찾으세요.</li>
<li>7번 출력의 최대값 및 최소값 인덱스 값을 찾으세요.</li>
<li>모양이 <code>(1, 1, 1, 10)</code>인 무작위 텐서를 만든 다음 값이 <code>1</code>인 모든 차원이 제거된 모양이 <code>(10)</code>인 새로운 텐서를 만드세요. 생성할 때 시드를 <code>7</code>로 설정하고 첫 번째 텐서와 그 모양, 두 번째 텐서와 그 모양을 출력하세요. 출력은 다음과 같아야 합니다.</li>
</ol>
<pre><code>tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,
           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])
tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,
        0.8513]) torch.Size([10])</code></pre>
<blockquote class="blockquote">
<p><strong>리소스:</strong> 이 연습 문제를 완료하려면 과정 GitHub에서 <a href="https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/exercises">연습 문제 노트북 템플릿</a> 및 잠재적인 <a href="https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions">솔루션</a>을 참조하세요.</p>
</blockquote>
</section>
<section id="추가-학습-자료" class="level2">
<h2 class="anchored" data-anchor-id="추가-학습-자료">추가 학습 자료</h2>
<ul>
<li>1시간 동안 <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">PyTorch 기본 튜토리얼</a>을 훑어보세요(<a href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">빠른 시작</a> 및 <a href="https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html">텐서</a> 섹션을 권장합니다).</li>
<li>텐서가 데이터를 어떻게 표현할 수 있는지 더 자세히 알아보려면 다음 비디오를 시청하세요: <a href="https://youtu.be/f5liqUk0ZTw">What’s a tensor?</a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link" aria-label="딥러닝을 위한 PyTorch 배우기">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">딥러닝을 위한 PyTorch 배우기</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./01_pytorch_workflow.html" class="pagination-link" aria-label="01 - PyTorch 워크플로우">
        <span class="nav-page-text"><span class="chapter-title">01 - PyTorch 워크플로우</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>